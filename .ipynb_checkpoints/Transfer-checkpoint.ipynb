{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras import optimizers \n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "from time import time\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(12)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(12)\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1001's data\n",
      "Loading 1002's data\n",
      "Loading 1003's data\n",
      "Loading 1004's data\n",
      "Loading 1005's data\n",
      "Loading 1006's data\n",
      "Loading 1007's data\n",
      "Loading 1008's data\n",
      "Loading 2001's data\n",
      "Loading 2002's data\n",
      "Finished loading\n"
     ]
    }
   ],
   "source": [
    "%run load_dataset.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprecessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run preprocess_for_NN.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_class = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(num_class, activation='softmax')(x)\n",
    "\n",
    "# Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', mode='max', factor=0.1, patience=10,\n",
    "                                verbose=1, min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=20, verbose=0, mode='max')\n",
    "\n",
    "model_2_path = \"./model/lab3_1/{}.h5\".format(\"model_2\")\n",
    "checkpoint = ModelCheckpoint(model_2_path, monitor='val_acc', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\n",
    "callbacks_list = [checkpoint,early_stopper,reduce_lr]\n",
    "\n",
    "# Create and compile model\n",
    "model_2 = Model(inputs=base_model.input, outputs=output)\n",
    "model_2.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=0.0001),metrics=[\"accuracy\", f1_score_metric])\n",
    "\n",
    "# Load last epoch model\n",
    "pretrined_model_2_path = \"./model/const_models/lab3_1/model_2.h5\"\n",
    "model_2.load_weights(pretrined_model_2_path)\n",
    "\n",
    "## Run until early stopping\n",
    "num_training_img=240\n",
    "num_validation_img=80\n",
    "stepsPerEpoch = num_training_img/batch_size\n",
    "validationSteps= num_validation_img/batch_size\n",
    "model_2.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=stepsPerEpoch,\n",
    "        epochs=5,\n",
    "        callbacks = callbacks_list,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps=validationSteps\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
