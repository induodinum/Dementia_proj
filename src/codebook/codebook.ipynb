{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "from os import listdir\n",
    "from sklearn.metrics import f1_score\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddc_path = 'E:/coding/Dementia_proj/src/ddc/'\n",
    "os.chdir(ddc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = '../../DDC_Data/raw/'\n",
    "basepath = '../../'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Actual Timestamp Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_timer(subject_id):\n",
    "    \n",
    "    sid_dir = mypath + subject_id\n",
    "    sid_files = [f for f in listdir(sid_dir) if 'history_amdtimer' in f]\n",
    "\n",
    "    sid_filepath = sid_dir + '/' + sid_files[0]\n",
    "\n",
    "    timer_df = pd.read_csv(sid_filepath, header=None, names=['sid','raw_label', 'timestamp', 'duration','label'])\n",
    "\n",
    "    filtered_timer = [i for i in timer_df['sid'] if i==int(subject_id)]\n",
    "\n",
    "    timer_filt = timer_df[timer_df['sid'].isin(filtered_timer)]\n",
    "    timer_filt = timer_filt.reset_index(drop=True)\n",
    "    \n",
    "    timer_label = []\n",
    "    \n",
    "    for i in range(len(timer_filt)):\n",
    "        if(timer_filt.loc[i]['raw_label']=='upstairs' or \n",
    "          timer_filt.loc[i]['raw_label']=='downstairs'):\n",
    "            timer_label.append('walk')\n",
    "        else:\n",
    "            timer_label.append(timer_filt.loc[i]['raw_label'])\n",
    "\n",
    "    timer_filt['label'] = pd.Series(timer_label)\n",
    "    \n",
    "    datetime_format = '%Y-%m-%d %H:%M:%S.%f'\n",
    "    timer_filt['time_start'] = timer_filt['timestamp'].apply(lambda x: datetime.strptime(x, datetime_format))\n",
    "    \n",
    "    time_format = '%H:%M:%S'\n",
    "    zero_date = datetime(1900, 1, 1)\n",
    "    \n",
    "    timer_filt['duration'] = timer_filt['duration'].apply(lambda x: datetime.strptime(x, time_format)-zero_date)\n",
    "    \n",
    "    for i in range(timer_filt.shape[0]):\n",
    "        timer_filt.loc[i, 'time_end'] = timer_filt.loc[i, 'time_start'] + timer_filt.loc[i, 'duration']\n",
    "\n",
    "#     print(timer_filt)\n",
    "    \n",
    "    return timer_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data of the Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_acc(subject_id, start_time, end_time):\n",
    "    # Load accelerations\n",
    "    acc_path = mypath + '/' + subject_id + '/' + subject_id + '-log_acc.csv'\n",
    "\n",
    "    df = pd.read_csv(acc_path, header=None, names=['x','y','z','timestamp'])\n",
    "    \n",
    "    datetime_format = '%Y-%m-%d %H:%M:%S.%f'\n",
    "    df['timestamp'] = df['timestamp'].apply(lambda x: datetime.strptime(x, datetime_format))\n",
    "\n",
    "    filtered = [r for r in df['timestamp'] if r>=start_time and r<=end_time]\n",
    "\n",
    "    df_filt = df[df['timestamp'].isin(filtered)]\n",
    "    df_filt = df_filt.reset_index(drop=True)\n",
    "\n",
    "    df_filt['ID'] = pd.Series([subject_id for i in range(len(df_filt))])\n",
    "    \n",
    "    cols = ['ID','timestamp','x','y','z']\n",
    "    df_filt = df_filt[cols]\n",
    "\n",
    "    return df_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hr(subject_id, start_time, end_time):\n",
    "    # Load heart rate\n",
    "    hr_filepath = mypath + '/' + subject_id + '/' + subject_id + '-log_hr.csv'\n",
    "\n",
    "    df2 = pd.read_csv(hr_filepath, header=None, names=['hr','timestamp'])\n",
    "    \n",
    "    datetime_format = '%Y-%m-%d %H:%M:%S.%f'\n",
    "    df2['timestamp'] = df2['timestamp'].apply(lambda x: datetime.strptime(x, datetime_format))\n",
    "\n",
    "    filtered = [r for r in df2['timestamp'] if r>=start_time and r<=end_time]\n",
    "\n",
    "    df_hr = df2[df2['timestamp'].isin(filtered)]\n",
    "    df_hr = df_hr.reset_index(drop=True)\n",
    "\n",
    "    cols = ['timestamp','hr']\n",
    "    df_hr = df_hr[cols]\n",
    "\n",
    "    return df_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_acc_and_hr(df_filt, df_hr):\n",
    "    # Fill in missing HRs\n",
    "    hr_cnt = 0\n",
    "\n",
    "    for i in range(len(df_filt)):\n",
    "        hr_time = df_hr.loc[hr_cnt,'timestamp']\n",
    "        filt_time = df_filt.loc[i,'timestamp']\n",
    "\n",
    "        if(hr_time<=filt_time):\n",
    "            if(hr_cnt<len(df_hr)-1):\n",
    "                hr_cnt += 1\n",
    "        df_filt.loc[i,'HR'] = df_hr.loc[hr_cnt,'hr']\n",
    "\n",
    "    # Normalize by dividing by g (standard gravity)\n",
    "    g = 9.8\n",
    "    df_filt.loc[:,'x'] = df_filt['x'].apply(lambda x: x/g)\n",
    "    df_filt.loc[:,'y'] = df_filt['y'].apply(lambda x: x/g)\n",
    "    df_filt.loc[:,'z'] = df_filt['z'].apply(lambda x: x/g)\n",
    "    \n",
    "    cols = ['x','y','z']\n",
    "    xyz_ = df_filt[cols].to_dict('split')['data']\n",
    "    xyz_new = MinMaxScaler().fit_transform(xyz_)\n",
    "\n",
    "    for i in range(len(cols)):\n",
    "        df_filt[cols[i]] = pd.Series(xyz_new.transpose()[i])\n",
    "        \n",
    "#     print(df_filt['x'])\n",
    "\n",
    "    return df_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Activity Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_i_bar = [0.00349329,0.00465817,0.00543154]\n",
    "std_i_bar = np.array(std_i_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equation_bai(X_i):\n",
    "    all_std = []\n",
    "    \n",
    "    std_i = np.std(X_i,axis=0)\n",
    "    diff_std = std_i**2 - std_i_bar**2\n",
    "    diff_std = (diff_std + 1) / (std_i_bar**2 + 1)\n",
    "    \n",
    "    diff_std_ = std_i**2\n",
    "\n",
    "    all_std.append(diff_std)\n",
    "    \n",
    "    all_std = np.array(all_std)\n",
    "    \n",
    "    ai = np.sum(all_std**2,axis=1)/3\n",
    "    ai[ai<0] = 0\n",
    "    ai = np.sqrt(ai)\n",
    "    \n",
    "    return ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ai(df1):\n",
    "    H = 10\n",
    "    ai1 = []\n",
    "\n",
    "    for i in range(len(df1)):\n",
    "        xyz_val = []\n",
    "        if(i-H>=0):\n",
    "            for j in range(H,0,-1):\n",
    "                xyz_val.append([df1.loc[i-j,'x'],df1.loc[i-j,'y'],df1.loc[i-j,'z']])\n",
    "            ai_val = float(equation_bai(xyz_val))\n",
    "            ai1.append(ai_val)\n",
    "        else:\n",
    "            ai1.append(1)\n",
    "\n",
    "    return ai1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess (PCA, impure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df_test, pca):\n",
    "    ts_list = []\n",
    "    g = 9.8\n",
    "\n",
    "    X_list = []\n",
    "    \n",
    "    for i in range(len(df_test)):\n",
    "        X_i = [df_test.loc[i]['x']/g, df_test.loc[i]['y']/g, df_test.loc[i]['z']/g]\n",
    "        X_list.append(X_i)\n",
    "        \n",
    "    X_stack = np.vstack(X_list)\n",
    "    X_norm = MinMaxScaler().fit_transform(X_stack)\n",
    "    X_pca = pca.transform(X_norm)\n",
    "\n",
    "    y_imp = [-1 for i in range(X_pca.shape[0])]\n",
    "    X_imp, y_imp = prepare_impure_label(X_pca, y_imp)\n",
    "    \n",
    "    return X_imp, y_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run classifier_algo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_combine(X_imp, model, window_length=60):\n",
    "    \n",
    "    y_pred = model.predict(X_imp)\n",
    "    print(\"Finished prediction\")\n",
    "    \n",
    "#     y_pred = combine_2(X_imp, y_pred)\n",
    "#     y_pred_fill = np.hstack(([y_pred[0] for i in range(window_length-1)], y_pred))\n",
    "    \n",
    "#     print(X_imp.shape, y_pred_fill.shape)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group dataframe by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_dataframe_by_label(df1, df_timer, subject_id, label_list):\n",
    "    df_list = {}\n",
    "    period = {}\n",
    "    \n",
    "    for label in label_list:\n",
    "        df_list[label] = pd.DataFrame()\n",
    "        period[label] = []\n",
    "    \n",
    "    for label in label_list:\n",
    "#         print(label)\n",
    "        for i in range(df_timer.shape[0]):\n",
    "            start = 0\n",
    "            end = 0\n",
    "            \n",
    "            if(df_timer.loc[i, 'label']==label):\n",
    "                t_a = df_timer.loc[i, 'time_start']\n",
    "                t_b = df_timer.loc[i, 'time_end']\n",
    "\n",
    "                for j in range(df1.shape[0]):    \n",
    "                    if(df1.loc[j, 'ID']==subject_id):\n",
    "                        if(j>0 and df1.loc[j, 'timestamp']<=t_b and df1.loc[j-1, 'timestamp']<t_b):\n",
    "                            end = j\n",
    "\n",
    "                for j in reversed(range(df1.shape[0])):\n",
    "                    if(df1.loc[j, 'ID']==subject_id):\n",
    "                        if(j<df1.shape[0]-1 and df1.loc[j, 'timestamp']>=t_a and df1.loc[j+1, 'timestamp']>t_a):\n",
    "                            start = j\n",
    "\n",
    "                period[label].append([start, end])\n",
    "                \n",
    "                if(df_list[label].empty):\n",
    "                    df_list[label] = df1.loc[start:end+1]\n",
    "                else:\n",
    "                    df_list[label].append(df1.loc[start:end+1], ignore_index=True)\n",
    "                    \n",
    "    for label in label_list:\n",
    "        df_list[label] = df_list[label].reset_index(drop=True)\n",
    "\n",
    "    return df_list, period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Predicted Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_periods_from_list(y_pred, label_list):\n",
    "    \n",
    "    pred_periods = [[] for i in range(len(label_list))]\n",
    "\n",
    "    keep = 0\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        keep_lb = y_pred[keep]\n",
    "\n",
    "        if(keep_lb!=y_pred[i]):\n",
    "            \n",
    "            if(y_pred[i]!=None):\n",
    "                pred_periods[y_pred[i-1]].append([keep, i-1])               \n",
    "\n",
    "            keep = i\n",
    "\n",
    "        elif(i==len(y_pred)-1):\n",
    "\n",
    "            if(y_pred[i]!=None):\n",
    "                pred_periods[y_pred[i-1]].append([keep, i]) \n",
    "\n",
    "    pred_periods = np.array(pred_periods)\n",
    "    \n",
    "    return pred_periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_predicted(pred_periods, y_length):\n",
    "    onesec = 1  # 1 sec.\n",
    "    T = 0.16    # T = 1/f\n",
    "\n",
    "    pp_periods = []\n",
    "    \n",
    "    for pp in pred_periods:\n",
    "        pp_i = pred_periods[pp]\n",
    "        \n",
    "        temp = []\n",
    "        for p in pp_i:\n",
    "            if(p[1]-p[0]>int(onesec*2*(1/T))):\n",
    "                temp.append([p[0],p[1]])\n",
    "                \n",
    "        pp_periods.append(temp)\n",
    "\n",
    "    pp_periods = np.array(pp_periods)\n",
    "    \n",
    "    other_label = -1\n",
    "    all_run = [other_label for i in range(y_length)]\n",
    "\n",
    "    for i in range(len(pp_periods)):\n",
    "        for p in pp_periods[i]:\n",
    "            for j in range(p[0],p[1]+1):\n",
    "                all_run[j] = i\n",
    "\n",
    "    for i in range(len(all_run)-1,0,-1):\n",
    "        if(all_run[i-1]==other_label):\n",
    "            all_run[i-1] = all_run[i]\n",
    "\n",
    "    return all_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get sequence from periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_from_periods(periods, label_list):\n",
    "    \n",
    "    max_length = 0\n",
    "    \n",
    "    for label in label_list:\n",
    "        if(len(periods[label])>0):\n",
    "            periods_i = np.hstack(periods[label])\n",
    "        \n",
    "            if(max_length<max(periods_i)):\n",
    "                max_length = max(periods_i)\n",
    "    \n",
    "    seq = ['' for i in range(max_length+1)]\n",
    "    \n",
    "    for label in label_list:\n",
    "        for element in periods[label]:\n",
    "            for i in range(element[0], element[1]+1):\n",
    "                seq[i] = label\n",
    "    \n",
    "    return seq, max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_period(p1, p2, max_length, label_list):\n",
    "    iou_all = []\n",
    "    \n",
    "    for lb in label_list:\n",
    "        p1_onehot = []\n",
    "        for i in range(max_length):\n",
    "            if(p1[i]==lb):\n",
    "                p1_onehot.append(1)\n",
    "            else:\n",
    "                p1_onehot.append(0)\n",
    "                \n",
    "        p2_onehot = []\n",
    "        for i in range(max_length):\n",
    "            if(p2[i]==lb):\n",
    "                p2_onehot.append(1)\n",
    "            else:\n",
    "                p2_onehot.append(0)\n",
    "                \n",
    "        intersection = 0\n",
    "        union = 0\n",
    "        \n",
    "        for i in range(max_length):\n",
    "            if(p1_onehot[i]==1 and p2_onehot[i]==1):\n",
    "                intersection += 1\n",
    "            if(p1_onehot[i]==1 or p2_onehot[i]==1):\n",
    "                union += 1\n",
    "                \n",
    "        iou_lb = intersection/union\n",
    "        \n",
    "        iou_all.append(iou_lb)\n",
    "        \n",
    "    return iou_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data(subject_id, label_list):\n",
    "    \n",
    "    print(\"Loading {0}'s data\".format(subject_id))\n",
    "\n",
    "    df_timer = load_timer(subject_id)\n",
    "    \n",
    "    start_time = df_timer.loc[0, 'time_start']\n",
    "    end_time = df_timer.loc[df_timer.shape[0]-1, 'time_end']\n",
    "\n",
    "    df_acc = load_acc(subject_id, start_time, end_time)\n",
    "    df_hr = load_hr(subject_id, start_time, end_time)\n",
    "\n",
    "    df1 = merge_acc_and_hr(df_acc, df_hr)\n",
    "    ai1 = calc_ai(df1)\n",
    "\n",
    "    df1['AI'] = pd.Series(ai1)\n",
    "    \n",
    "    df_acc_label, true_periods = group_dataframe_by_label(df1, df_timer, subject_id, label_list)\n",
    "    \n",
    "    return df_acc_label, true_periods\n",
    "\n",
    "#     X_impure, y_impure = preprocess_data(df_acc, pca)\n",
    "#     y_pred = predict_combine(X_impure, model)\n",
    "#     p_periods = get_periods_from_list(y_pred, label_list)\n",
    "#     pred_periods = {}\n",
    "\n",
    "#     for i in range(len(label_list)):\n",
    "#         pred_periods[label_list[i]] = p_periods[i]\n",
    "    \n",
    "#     pp_all = postprocess_predicted(pred_periods, len(y_pred))\n",
    "    \n",
    "#     p_true, len_true = sequence_from_periods(true_periods, label_list)\n",
    "#     p_pred, len_pred = sequence_from_periods(pred_periods, label_list)\n",
    "    \n",
    "#     iou = evaluate_period(p_true, p_pred, len_pred, label_list)\n",
    "    \n",
    "#     print('label:', label_list)\n",
    "#     print('iou:', iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1001', '1002', '1003', '1004', '1005', '1006', '1007', '1008', '1009', '1010', '1011', '1012', '1013', '1014', '1015', '1016', '1017', '1018', '3001', '3002', '3003', '3004', '3005', '3006']\n",
      "Loading 1001's data\n",
      "(188, 7)\n",
      "(188, 7)\n",
      "(188, 7)\n",
      "(375, 7)\n",
      "Loading 1002's data\n",
      "(375, 7)\n",
      "(376, 7)\n",
      "(376, 7)\n",
      "(563, 7)\n",
      "Loading 1003's data\n",
      "(569, 7)\n",
      "(563, 7)\n",
      "(564, 7)\n",
      "(937, 7)\n",
      "Loading 1004's data\n",
      "(757, 7)\n",
      "(750, 7)\n",
      "(752, 7)\n",
      "(1311, 7)\n",
      "Loading 1005's data\n",
      "(945, 7)\n",
      "(938, 7)\n",
      "(940, 7)\n",
      "(1686, 7)\n",
      "Loading 1006's data\n",
      "(1133, 7)\n",
      "(1125, 7)\n",
      "(1128, 7)\n",
      "(2060, 7)\n",
      "Loading 1007's data\n",
      "(1320, 7)\n",
      "(1313, 7)\n",
      "(1316, 7)\n",
      "(2441, 7)\n",
      "Loading 1008's data\n",
      "(1507, 7)\n",
      "(1501, 7)\n",
      "(1504, 7)\n",
      "(2816, 7)\n",
      "Loading 1009's data\n",
      "(1702, 7)\n",
      "(1689, 7)\n",
      "(1692, 7)\n",
      "(3029, 7)\n",
      "Loading 1010's data\n",
      "(1890, 7)\n",
      "(1884, 7)\n",
      "(1880, 7)\n",
      "(3217, 7)\n",
      "Loading 1011's data\n",
      "(2078, 7)\n",
      "(2072, 7)\n",
      "(2068, 7)\n",
      "(3405, 7)\n",
      "Loading 1012's data\n",
      "(2266, 7)\n",
      "(2260, 7)\n",
      "(2255, 7)\n",
      "(3593, 7)\n",
      "Loading 1013's data\n",
      "(2454, 7)\n",
      "(2448, 7)\n",
      "(2442, 7)\n",
      "(3781, 7)\n",
      "Loading 1014's data\n",
      "(2641, 7)\n",
      "(2641, 7)\n",
      "(2629, 7)\n",
      "(3974, 7)\n",
      "Loading 1015's data\n",
      "(2741, 7)\n",
      "(2816, 7)\n",
      "(2723, 7)\n",
      "(4075, 7)\n",
      "Loading 1016's data\n",
      "(2928, 7)\n",
      "(3010, 7)\n",
      "(2910, 7)\n",
      "(4386, 7)\n",
      "Loading 1017's data\n",
      "(3028, 7)\n",
      "(3198, 7)\n",
      "(3035, 7)\n",
      "(4698, 7)\n",
      "Loading 1018's data\n",
      "(3153, 7)\n",
      "(3322, 7)\n",
      "(3142, 7)\n",
      "(4917, 7)\n",
      "Loading 3001's data\n",
      "(3341, 7)\n",
      "(3510, 7)\n",
      "(3336, 7)\n",
      "(5111, 7)\n",
      "Loading 3002's data\n",
      "(3529, 7)\n",
      "(3698, 7)\n",
      "(3524, 7)\n",
      "(5299, 7)\n",
      "Loading 3003's data\n",
      "(3717, 7)\n",
      "(3885, 7)\n",
      "(3711, 7)\n",
      "(5678, 7)\n",
      "Loading 3004's data\n",
      "(3905, 7)\n",
      "(4079, 7)\n",
      "(3899, 7)\n",
      "(6051, 7)\n",
      "Loading 3005's data\n",
      "(4093, 7)\n",
      "(4273, 7)\n",
      "(4087, 7)\n",
      "(6418, 7)\n",
      "Loading 3006's data\n",
      "(4281, 7)\n",
      "(4460, 7)\n",
      "(4274, 7)\n",
      "(6612, 7)\n",
      "finished loading\n"
     ]
    }
   ],
   "source": [
    "all_subjects = [range(1001, 1019), range(3001, 3007)]\n",
    "all_subjects = np.hstack(all_subjects)\n",
    "all_subjects = [str(i) for i in all_subjects]\n",
    "print(all_subjects)\n",
    "\n",
    "label_list = ['sit', 'sleep', 'stand', 'walk']\n",
    "\n",
    "df_all_label = {}\n",
    "for label in label_list:\n",
    "    df_all_label[label] = pd.DataFrame()\n",
    "# print(df_all_label)\n",
    "\n",
    "for subject_id in all_subjects:\n",
    "    df_label, true_periods = load_all_data(subject_id, label_list)\n",
    "    \n",
    "    for label in label_list:\n",
    "        \n",
    "        if(df_all_label[label].empty):\n",
    "            df_all_label[label] = df_label[label]\n",
    "        else:\n",
    "            df_all_label[label] = df_all_label[label].append(df_label[label], ignore_index=True)\n",
    "            \n",
    "        print(df_all_label[label].shape)\n",
    "            \n",
    "print('finished loading')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe slice functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_dataframe(df, col, segment_length=24):\n",
    "    df_list = []\n",
    "    \n",
    "    for i in range(df.shape[0]-segment_length):\n",
    "        df_segment = df.loc[i:i+segment_length-1][col]\n",
    "        df_list.append(list(df_segment))\n",
    "        \n",
    "    return np.array(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_sliced(df_all_label, label_list):\n",
    "    df_sliced = {}\n",
    "    slice_labels = []\n",
    "    \n",
    "    cols = ['x', 'y', 'z']\n",
    "    \n",
    "    for i, c in enumerate(cols):\n",
    "        df_sliced[c] = []\n",
    "        \n",
    "        for lb in label_list:\n",
    "            df_slice_lb_c = slice_dataframe(df_all_label[lb], c)\n",
    "            print(df_slice_lb_c.shape)\n",
    "            \n",
    "            df_sliced[c].append(df_slice_lb_c)    # append every label to an array of axis c\n",
    "    \n",
    "        df_sliced[c] = np.array([item for sublist in df_sliced[c] for item in sublist])\n",
    "    \n",
    "    return df_sliced\n",
    "                        \n",
    "#     for label in label_list:\n",
    "#         df_slice_i = slice_dataframe(df_all_label[label], slice_length)\n",
    "#         slice_labels.append([label for i in range(df_slice_i.shape[0])])\n",
    "        \n",
    "#         df_slice_list.append(df_slice_i)\n",
    "        \n",
    "#     slice_list = [item for sublist in df_slice_list for item in sublist]\n",
    "#     slice_list = [np.hstack(x) for x in slice_list]\n",
    "    \n",
    "#     slice_labels = np.hstack(slice_labels)\n",
    "        \n",
    "#     return np.array(slice_list), np.array(slice_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create histograms for each slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    return v / np.linalg.norm(v) if np.linalg.norm(v)!=0 else v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_cluster_center_idx(slice_i, cluster_centers):\n",
    "    min_dist = math.inf\n",
    "    cluster_idx = 0\n",
    "    for i, cluster in enumerate(cluster_centers):\n",
    "        dist_i = np.linalg.norm(cluster-slice_i)\n",
    "        if(dist_i<min_dist):\n",
    "            min_dist = dist_i\n",
    "            cluster_idx = i\n",
    "            \n",
    "    return cluster_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_for_all_slices(df_sliced_c):\n",
    "    kmeans = KMeans(n_clusters=128, random_state=42).fit(df_sliced_c)\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    \n",
    "    histogram = [0 for i in range(len(cluster_centers))]\n",
    "    \n",
    "    for slice_i in df_sliced_c:\n",
    "        histogram_idx = most_similar_cluster_center_idx(slice_i, cluster_centers)\n",
    "        \n",
    "        histogram[histogram_idx] += 1\n",
    "        \n",
    "    normalized_hist = normalize(histogram)\n",
    "    \n",
    "    return np.array(normalized_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4257, 24)\n",
      "(4436, 24)\n",
      "(4250, 24)\n",
      "(6588, 24)\n",
      "(4257, 24)\n",
      "(4436, 24)\n",
      "(4250, 24)\n",
      "(6588, 24)\n",
      "(4257, 24)\n",
      "(4436, 24)\n",
      "(4250, 24)\n",
      "(6588, 24)\n"
     ]
    }
   ],
   "source": [
    "df_sliced = get_df_sliced(df_all_label, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_hist = {}\n",
    "cols = ['x', 'y', 'z']\n",
    "\n",
    "for c in cols:\n",
    "    normalized_hist[c] = histogram_for_all_slices(df_sliced[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19531, 24)\n",
      "-------\n",
      "(19531, 24)\n",
      "-------\n",
      "(19531, 24)\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for c in cols:\n",
    "    print(df_sliced[c].shape)\n",
    "    print('-------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recycle bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in label_list:\n",
    "        segments_i = [df_all_label[label][a:a+seg_length] for a in range(0, df_all_label[label].shape[0], seg_length)]\n",
    "    \n",
    "        print(len(segments_i[-1]))\n",
    "        \n",
    "        \n",
    "##############\n",
    "\n",
    "slice_y.append([label for i in range(df_all_label[label].shape[0])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
