{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "\n",
    "from os import listdir, walk\n",
    "from os.path import isfile, join\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Timestamp Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sec(time):\n",
    "    hms = time.split(':')\n",
    "    hms = [float(x) for x in hms]\n",
    "    sec = hms[2] + hms[1]*60 + hms[0]*3600\n",
    "    sec = round(sec,3)\n",
    "    return sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ts(sec):\n",
    "    ts = ''\n",
    "    hr = int(sec/3600)\n",
    "    mn = int((sec - (hr*3600))/60)\n",
    "    sc = sec - (hr*3600) - (mn*60)\n",
    "    sc = round(sc,3)\n",
    "    ts += str(hr) + ':' + str(mn) + ':' + str(sc)\n",
    "    # print(ts)\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_t_period(dates,secs):\n",
    "    t_period = []\n",
    "    \n",
    "    start_sec = secs[0]\n",
    "    prev_sec = secs[0]\n",
    "    prev_date = dates[0]\n",
    "\n",
    "    for i in range(len(secs)):\n",
    "        curr_sec = secs[i]\n",
    "        diff_sec = curr_sec - prev_sec\n",
    "        curr_date = dates[i]\n",
    "        \n",
    "        if((diff_sec>3.0) and (curr_date==prev_date)):\n",
    "            t_period.append([curr_date,start_sec,prev_sec])\n",
    "            start_sec = curr_sec\n",
    "        elif(curr_date!=prev_date):\n",
    "            t_period.append([prev_date,start_sec,prev_sec])\n",
    "            start_sec = curr_sec\n",
    "            prev_date = curr_date\n",
    "        elif(i==len(secs)-1):\n",
    "            t_period.append([curr_date,start_sec,curr_sec])\n",
    "\n",
    "        prev_sec = curr_sec\n",
    "    \n",
    "    return t_period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve file directories from Google Drive\n",
    "mypath = '../../DDC_Data/raw/'\n",
    "basepath = '../../'\n",
    "\n",
    "dir_ = [f for f in walk(mypath)]\n",
    "# print(dir_)\n",
    "\n",
    "dir = list(dir_[0])\n",
    "dir[1] = sorted(dir[1])\n",
    "\n",
    "outer_path = dir[0]\n",
    "sub_path = dir[1]\n",
    "\n",
    "folders = [join(outer_path,d) for d in sub_path]\n",
    "\n",
    "files = []\n",
    "for fd in folders:\n",
    "    temp_f = [f for f in listdir(fd) if isfile(join(fd, f)) and f[-3:]=='csv' and f[5:9]!='data' and f[:4]==fd[-4:]]\n",
    "    temp_f = sorted(temp_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve All Timestamp Periods from a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects = []\n",
    "\n",
    "for i in range(1001,1015):\n",
    "    all_subjects.append(str(i))\n",
    "\n",
    "for i in range(3001,3007):\n",
    "    all_subjects.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_timer(subject_id):\n",
    "  # Configure starting and ending time values\n",
    "    sid_dir = mypath + '/' + subject_id\n",
    "    sid_files = [f for f in listdir(sid_dir) if 'history_amdtimer' in f]\n",
    "\n",
    "    sid_filepath = sid_dir + '/' + sid_files[0]\n",
    "\n",
    "    # Timestamp periods dataframe\n",
    "    timer_df = pd.read_csv(sid_filepath, header=None, names=['sid','raw_label', 'timestamp', 'duration','label'])\n",
    "\n",
    "    filtered_timer = [i for i in timer_df['sid'] if i==int(subject_id)]\n",
    "\n",
    "    timer_filt = timer_df[timer_df['sid'].isin(filtered_timer)]\n",
    "    timer_filt = timer_filt.reset_index(drop=True)\n",
    "    \n",
    "    timer_label = []\n",
    "    \n",
    "    for i in range(len(timer_label)):\n",
    "        if(timer_filt.loc[i]['raw_label']=='upstairs' or \n",
    "          timer_filt.loc[i]['raw_label']=='downstairs'):\n",
    "            timer_label.append('walk')\n",
    "        else:\n",
    "            timer_label.append(timer_filt.loc[i]['raw_label'])\n",
    "\n",
    "    timer_filt['label'] = pd.Series(timer_arr)\n",
    "    \n",
    "    datetime_format = '%Y-%m-%d %H:%M:%S.%f'\n",
    "    timer_filt['time_start'] = timer_filt['timestamp'].apply(lambda x: datetime.strptime(datetime_format))\n",
    "    \n",
    "    for i in range(timer_filt.shape[0]):\n",
    "        \n",
    "\n",
    "    rec_date = start_ts.split(' ')[0]\n",
    "    start_time = start_ts.split(' ')[1]\n",
    "    end_time = calc_ts(calc_sec(end_ts.split(' ')[1]) + \n",
    "                       calc_sec(timer_filt.loc[len(timer_filt)-1]['duration']))\n",
    "\n",
    "#     print(timer_filt)\n",
    "    \n",
    "    return timer_filt, rec_date, start_time, end_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe of ACC and HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_acc(subject_id, rec_date, start_time, end_time):\n",
    "    # Load accelerations\n",
    "    acc_filepath = mypath + '/' + subject_id + '/' + subject_id + '-log_acc.csv'\n",
    "\n",
    "    df = pd.read_csv(acc_filepath, header=None, names=['x','y','z','timestamp'])\n",
    "\n",
    "    filtered = [i for i in df['timestamp'] if str(i)[:10]==rec_date and calc_sec(str(i)[11:])>=calc_sec(start_time) \n",
    "              and calc_sec(str(i)[11:])<=calc_sec(end_time)]\n",
    "\n",
    "    df_filt = df[df['timestamp'].isin(filtered)]\n",
    "    df_filt = df_filt.reset_index(drop=True)\n",
    "\n",
    "    df_filt['ID'] = pd.Series([subject_id for i in range(len(df_filt))])\n",
    "    \n",
    "    cols = ['ID','timestamp','x','y','z']\n",
    "    df_filt = df_filt[cols]\n",
    "\n",
    "    return df_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hr(subject_id, rec_date, start_time, end_time):\n",
    "    # Load heart rate\n",
    "    hr_filepath = mypath + '/' + subject_id + '/' + subject_id + '-log_hr.csv'\n",
    "\n",
    "    df2 = pd.read_csv(hr_filepath, header=None, names=['hr','timestamp'])\n",
    "\n",
    "    filtered = [i for i in df2['timestamp'] if i[:10]==rec_date and calc_sec(i[11:])>=calc_sec(start_time) \n",
    "              and calc_sec(i[11:])<=calc_sec(end_time)]\n",
    "\n",
    "    df_hr = df2[df2['timestamp'].isin(filtered)]\n",
    "    df_hr = df_hr.reset_index(drop=True)\n",
    "\n",
    "    cols = ['timestamp','hr']\n",
    "    df_hr = df_hr[cols]\n",
    "\n",
    "    return df_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_acc_and_hr(df_filt, df_hr):\n",
    "    # Fill in missing HRs\n",
    "    hr_cnt = 0\n",
    "\n",
    "    for i in range(len(df_filt)):\n",
    "        hr_time = df_hr.loc[hr_cnt,'timestamp'].split(' ')[1]\n",
    "        filt_time = df_filt.loc[i,'timestamp'].split(' ')[1]\n",
    "\n",
    "        if(calc_sec(hr_time)<=calc_sec(filt_time)):\n",
    "            if(hr_cnt<len(df_hr)-1):\n",
    "                hr_cnt += 1\n",
    "        df_filt.loc[i,'HR'] = df_hr.loc[hr_cnt,'hr']\n",
    "\n",
    "    # Normalize by dividing by g (standard gravity)\n",
    "    g = 9.8\n",
    "    df_filt.loc[:,'x'] = df_filt['x'].apply(lambda x: x/g)\n",
    "    df_filt.loc[:,'y'] = df_filt['y'].apply(lambda x: x/g)\n",
    "    df_filt.loc[:,'z'] = df_filt['z'].apply(lambda x: x/g)\n",
    "    \n",
    "    cols = ['x','y','z']\n",
    "    xyz_ = df_filt[cols].to_dict('split')['data']\n",
    "    xyz_new = MinMaxScaler().fit_transform(xyz_)\n",
    "#     print(np.array(xyz_new).shape)\n",
    "\n",
    "    for i in range(len(cols)):\n",
    "        df_filt[cols[i]] = pd.Series(xyz_new.transpose()[i])\n",
    "        \n",
    "#     print(df_filt['x'])\n",
    "\n",
    "    return df_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Activity Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_i_bar = [0.00349329,0.00465817,0.00543154]\n",
    "std_i_bar = np.array(std_i_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equation_bai(X_i):\n",
    "    all_std = []\n",
    "    \n",
    "    std_i = np.std(X_i,axis=0)\n",
    "    diff_std = std_i**2 - std_i_bar**2\n",
    "    diff_std = (diff_std + 1) / (std_i_bar**2 + 1)\n",
    "    \n",
    "    diff_std_ = std_i**2\n",
    "\n",
    "    all_std.append(diff_std)\n",
    "    \n",
    "    all_std = np.array(all_std)\n",
    "    \n",
    "    ai = np.sum(all_std**2,axis=1)/3\n",
    "    ai[ai<0] = 0\n",
    "    ai = np.sqrt(ai)\n",
    "    \n",
    "    return ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ai(df1):\n",
    "    H = 10\n",
    "    ai1 = []\n",
    "\n",
    "    for i in range(len(df1)):\n",
    "        xyz_val = []\n",
    "        if(i-H>=0):\n",
    "            for j in range(H,0,-1):\n",
    "                xyz_val.append([df1.loc[i-j,'x'],df1.loc[i-j,'y'],df1.loc[i-j,'z']])\n",
    "            ai_val = float(equation_bai(xyz_val))\n",
    "            ai1.append(ai_val)\n",
    "        else:\n",
    "            ai1.append(1)\n",
    "\n",
    "    return ai1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colors for Each Acitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_time_periods(df_timer):\n",
    "    t_ = [calc_sec(t.split(' ')[1]) for t in df_timer['timestamp']]\n",
    "    duration = [d for d in df_timer['duration']]\n",
    "    lb_ = [lb for lb in df_timer['label']]\n",
    "\n",
    "    t_end = [t_[i]+calc_sec(duration[i]) for i in range(len(t_))]  \n",
    "\n",
    "    ts_ = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(t_)):\n",
    "        ts_.append(calc_sec(duration[i]))\n",
    "        labels.append(lb_[i])\n",
    "        if(i+1<len(t_)):\n",
    "            ts_.append(round(t_[i+1]-t_end[i],3))\n",
    "            labels.append('NaN')\n",
    "\n",
    "    return ts_, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_color_labels(ts_, labels):\n",
    "  \n",
    "    accum = 0\n",
    "    ts = []\n",
    "    for x in ts_:\n",
    "        accum += x\n",
    "        ts.append(round(accum,3))\n",
    "\n",
    "    lb_set = set()\n",
    "    for x in labels:\n",
    "        lb_set.add(x)\n",
    "\n",
    "    lb_ = list(lb_set)\n",
    "\n",
    "    set_cnt = []\n",
    "    for i in range(len(lb_)):\n",
    "        set_cnt.append(0)\n",
    "\n",
    "    lb = []\n",
    "    lb.append('NaN')\n",
    "\n",
    "    for x in labels:\n",
    "        for i in range(len(lb_)):\n",
    "            if(lb_[i]==x and set_cnt[i]!=1 and lb_[i]!='NaN'):\n",
    "                set_cnt[i] = 1\n",
    "                lb.append(x)\n",
    "\n",
    "    colors = ['#808080', '#E6194B', '#3CB44B', '#FFE119', '#4363D8', '#F58231',\n",
    "            '#911EB4', '#46F0F0', '#F032E6', '#BCF60C', '#008080', '#E6BEFF', \n",
    "            '#9A6324', '#800000', '#AAFFC3', '#808000', '#000075']\n",
    "\n",
    "    color_dict = {}\n",
    "    for i in range(len(lb)):\n",
    "        color_dict[lb[i]] = colors[i]\n",
    "\n",
    "    #   print(color_dict)\n",
    "\n",
    "    lb_color = []\n",
    "    for x in labels:\n",
    "        lb_color.append(color_dict[x])\n",
    "\n",
    "    return ts, lb_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ACC, AI with Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ai(df1, ts, lb_color):\n",
    "    dict1 = df1.to_dict(orient='list')\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(16,12))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    ts_cnt = 0\n",
    "    x_axis = []\n",
    "    y_ai = []\n",
    "\n",
    "    ax = axes[0]\n",
    "    ax.plot(dict1['x'],color='r',label='X')\n",
    "    ax.plot(dict1['y'],color='g',label='Y')\n",
    "    ax.plot(dict1['z'],color='b',label='Z')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_title('X,Y,Z')\n",
    "\n",
    "    ax = axes[1]\n",
    "    for i in range(len(dict1['timestamp'])):\n",
    "        if(dict1['AI'][i]>0):\n",
    "            if(calc_sec(dict1['timestamp'][i].split(' ')[1])>calc_sec(start_time)+ts[ts_cnt]):\n",
    "                ax.plot(x_axis,y_ai,color=lb_color[ts_cnt])\n",
    "                ts_cnt += 1\n",
    "                x_axis = []\n",
    "                y_ai = []\n",
    "\n",
    "            elif(ts_cnt==len(lb_color)-1):\n",
    "                ax.plot(x_axis,y_ai,color=lb_color[ts_cnt])\n",
    "\n",
    "            x_axis.append(i)\n",
    "            y_ai.append(dict1['AI'][i])\n",
    "\n",
    "    ax.set_title('Activity Index')\n",
    "\n",
    "    fig.savefig(basepath + 'Graphs/' + subject_id + '/' + subject_id + '_ddc_run.png', dpi = 300)\n",
    "\n",
    "    #   plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate Data by Labels of Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class period:\n",
    "    def __init__(self, s, f):\n",
    "        self.s = s\n",
    "        self.f = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_label(df1, df_timer, df_list, labels):\n",
    "  \n",
    "    df_label = df_timer.groupby('label')\n",
    "    td_col = ['timestamp','duration']\n",
    "    cols = ['x','y','z']\n",
    "\n",
    "    for x in df_label:\n",
    "    # x[0] is a label\n",
    "    # x[1] is a groupby object\n",
    "    \n",
    "        df_label_x = df_label.get_group(x[0])\n",
    "        df_label_x = df_label_x.reset_index(drop=True)\n",
    "\n",
    "        temp_ts = [[df_label_x.loc[a]['timestamp'].split(' ')[1], \n",
    "                    calc_ts( calc_sec(df_label_x.loc[a]['timestamp'].split(' ')[1])+\n",
    "                            calc_sec(df_label_x.loc[a]['duration']) )] \n",
    "                    for a in range(len(df_label_x))]\n",
    "        \n",
    "        for a in temp_ts:\n",
    "            filter_ = [i for i in df1['timestamp'] \n",
    "                    if calc_sec(i.split(' ')[1])>=calc_sec(a[0]) and calc_sec(i.split(' ')[1])<=calc_sec(a[1])]\n",
    "\n",
    "            df1_new = df1[df1['timestamp'].isin(filter_)]\n",
    "            df1_new = df1_new.reset_index(drop=True)\n",
    "            \n",
    "#             xyz_ = df1_new[cols].to_dict('split')['data']\n",
    "#             xyz_new = MinMaxScaler().fit_transform(xyz_)\n",
    "            \n",
    "#             for i in range(len(cols)):\n",
    "#                 df1_new[cols[i]] = pd.Series(xyz_new.transpose()[i])\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                if(labels[i]==x[0]):\n",
    "                    df_list[i] = df_list[i].append(df1_new, sort=False)\n",
    "\n",
    "    return df_list    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe List Grouped by Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_dataframe(df1, df_timer):\n",
    "    df_list = []\n",
    "    cols = ['timestamp','x','y','z','HR','AI']\n",
    "\n",
    "    lbl = set()\n",
    "    for tm in range(len(df_timer)):\n",
    "        lbl.add(df_timer.loc[tm]['label'])\n",
    "\n",
    "    LABELS = sorted(list(lbl))\n",
    "\n",
    "    # dictionary mapped from activity label to index\n",
    "    label_dict = {\n",
    "      'sit': 0,\n",
    "      'sleep': 1,\n",
    "      'stand': 2,\n",
    "      'walk': 3\n",
    "    }\n",
    "\n",
    "    for i in range(len(LABELS)):\n",
    "        df_null = pd.DataFrame(columns=cols)\n",
    "        df_null = df_null.fillna(0)\n",
    "\n",
    "        df_list.append(df_null)\n",
    "\n",
    "    df_list = separate_label(df1, df_timer, df_list, LABELS)\n",
    "\n",
    "    for i in range(len(df_list)):\n",
    "        df_list[i] = df_list[i].reset_index(drop=True)\n",
    "        \n",
    "#     print(len(df_list[3]))\n",
    "\n",
    "    return df_list, label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Plots of Grouped Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grouped_df(df_list, label_dict):\n",
    "    xyz = ['x','y','z']\n",
    "    xyz_color = ['r','g','b']\n",
    "\n",
    "    for x in label_dict:\n",
    "    #     print(label_dict[x])\n",
    "\n",
    "        figure = plt.figure(figsize=(20,6))\n",
    "        figure.tight_layout()\n",
    "\n",
    "        cnt = 1\n",
    "\n",
    "        for i in range(len(xyz)):\n",
    "            ax = plt.subplot(1, len(xyz), cnt)\n",
    "\n",
    "            ax.set_ylim(top=1.5, bottom=-3.0)\n",
    "            ax.plot(df_list[label_dict[x]][xyz[i]], label=xyz[i], color=xyz_color[i])\n",
    "            ax.legend(loc='upper right')\n",
    "            ax.set_title(xyz[i] + '-axis for activity ' + x + ' subject no. ' + subject_id)\n",
    "\n",
    "            cnt += 1\n",
    "\n",
    "        figure.savefig(basepath + 'Graphs/ddc_' + x + '/' + subject_id + '.png', dpi=300)\n",
    "\n",
    "    #     plt.show()\n",
    "\n",
    "    # close the figure\n",
    "    plt.close(figure) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get X and y from Dataset for Each Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df_list, label_dict):\n",
    "    feature_cols = ['x','y','z']\n",
    "    count = 0\n",
    "    \n",
    "    y_all = []\n",
    "    ts_all = []\n",
    "    hr_all = []\n",
    "    \n",
    "    for x in label_dict:\n",
    "#         print(x)\n",
    "    \n",
    "        X_series = df_list[label_dict[x]][feature_cols]\n",
    "\n",
    "        X_ = X_series.values.reshape((len(X_series),3))\n",
    "        y_ = np.array([label_dict[x] for i in range(len(df_list[label_dict[x]]))])\n",
    "        ts_ = np.array(df_list[label_dict[x]]['timestamp'])\n",
    "        hr_ = np.array(df_list[label_dict[x]]['HR'])\n",
    "\n",
    "          # 'downstairs': 0,\n",
    "          # 'sit': 1,\n",
    "          # 'sleep': 2,\n",
    "          # 'stand': 3,\n",
    "            \n",
    "        y_all.append(y_)\n",
    "        ts_all.append(ts_)\n",
    "        hr_all.append(hr_)\n",
    "        \n",
    "        if(count==0):\n",
    "            X_all = X_\n",
    "            count += 1\n",
    "\n",
    "        else:\n",
    "            X_all = np.vstack((X_all, X_))\n",
    "\n",
    "    y_all = np.hstack(y_all)\n",
    "    ts_all = np.hstack(ts_all)\n",
    "    hr_all = np.hstack(hr_all)\n",
    "    \n",
    "    return np.array(X_all), np.array(y_all), np.array(ts_all), np.array(hr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_data(X_i, y_i, ts_i, hr_i, subj_i):\n",
    "    df_ = pd.DataFrame({\n",
    "        'ID': subj_i,\n",
    "        'timestamp': ts_i,\n",
    "        'x': [x[0] for x in X_i],\n",
    "        'y': [x[1] for x in X_i],\n",
    "        'z': [x[2] for x in X_i],\n",
    "        'HR': hr_i,\n",
    "        'label': y_i\n",
    "    })\n",
    "    \n",
    "    df_sorted = df_.sort_values(by=['timestamp'])\n",
    "    \n",
    "    cols = ['x','y','z']\n",
    "    X_i = df_sorted[cols].values.tolist()\n",
    "    y_i = df_sorted['label'].values.tolist()\n",
    "    ts_i = df_sorted['timestamp'].values.tolist()\n",
    "    hr_i = df_sorted['HR'].values.tolist()\n",
    "    subj_i = df_sorted['ID'].values.tolist()\n",
    "    \n",
    "    return X_i, y_i, ts_i, hr_i, subj_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Call *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data(all_subjects):\n",
    "    \n",
    "    for subject_id in all_subjects:\n",
    "        print(\"Loading {0}'s data\".format(subject_id))\n",
    "\n",
    "        df_timer, rec_date, start_time, end_time = load_timer(subject_id)\n",
    "        \n",
    "        df_filt = load_acc(subject_id, rec_date, start_time, end_time)\n",
    "        df_hr = load_hr(subject_id, rec_date, start_time, end_time)\n",
    "\n",
    "        df1 = merge_acc_and_hr(df_filt, df_hr)\n",
    "        ai1 = calc_ai(df1)\n",
    "\n",
    "        df1['AI'] = pd.Series(ai1)\n",
    "\n",
    "        ts_, labels = prepare_time_periods(df_timer)\n",
    "        ts, lb_color = prepare_color_labels(ts_, labels)\n",
    "        \n",
    "        df1['Label'] = pd.Series(labels)\n",
    "        \n",
    "#         print(start_time, end_time)\n",
    "        print\n",
    "        print(df1.head(8))\n",
    "\n",
    "        # get a list of dataframe in which there are 4 types of activity\n",
    "        df_list, label_dict = group_dataframe(df1, df_timer)\n",
    "        label_list = sorted(list(label_dict.keys()))\n",
    "\n",
    "    #     plot_grouped_df(df_list, label_dict)\n",
    "    #     plot_ai(df1, ts, lb_color)\n",
    "\n",
    "        X_i, y_i, ts_i, hr_i = get_data(df_list, label_dict)\n",
    "        subj_i = [subject_id for i in range(len(X_i))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1001's data\n",
      "     ID                timestamp         x         y         z         HR  \\\n",
      "0  1001  2019-01-14 14:52:31.035  0.232240  0.684961  0.471288  86.937775   \n",
      "1  1001  2019-01-14 14:52:31.193  0.231985  0.686028  0.469237  86.937775   \n",
      "2  1001  2019-01-14 14:52:31.356  0.232240  0.686242  0.470903  86.937775   \n",
      "3  1001  2019-01-14 14:52:31.514  0.232751  0.686135  0.470903  86.937775   \n",
      "4  1001  2019-01-14 14:52:31.675  0.232751  0.685495  0.471928  87.511505   \n",
      "5  1001  2019-01-14 14:52:31.836  0.233091  0.686562  0.471288  87.511505   \n",
      "6  1001  2019-01-14 14:52:31.997  0.232240  0.686775  0.472441  87.511505   \n",
      "7  1001  2019-01-14 14:52:32.158  0.232240  0.686028  0.471288  87.511505   \n",
      "\n",
      "    AI  Label  \n",
      "0  1.0  stand  \n",
      "1  1.0    NaN  \n",
      "2  1.0    sit  \n",
      "3  1.0    NaN  \n",
      "4  1.0  stand  \n",
      "5  1.0    NaN  \n",
      "6  1.0  sleep  \n",
      "7  1.0    NaN  \n",
      "Loading 1002's data\n",
      "     ID                timestamp         x         y         z          HR  \\\n",
      "0  1002  2019-01-14 15:19:07.994  0.443128  0.362208  0.296013  115.000565   \n",
      "1  1002  2019-01-14 15:19:08.155  0.446504  0.344085  0.287679  115.000565   \n",
      "2  1002  2019-01-14 15:19:08.321  0.443972  0.356485  0.295243  116.214920   \n",
      "3  1002  2019-01-14 15:19:08.477  0.447349  0.349201  0.293577  116.214920   \n",
      "4  1002  2019-01-14 15:19:08.637  0.450725  0.357439  0.285499  116.214920   \n",
      "5  1002  2019-01-14 15:19:08.797  0.437099  0.362815  0.298833  116.214920   \n",
      "6  1002  2019-01-14 15:19:08.957  0.439752  0.330125  0.287935  116.214920   \n",
      "7  1002  2019-01-14 15:19:09.118  0.456151  0.368971  0.277422  116.214920   \n",
      "\n",
      "    AI  Label  \n",
      "0  1.0  stand  \n",
      "1  1.0    NaN  \n",
      "2  1.0    sit  \n",
      "3  1.0    NaN  \n",
      "4  1.0  stand  \n",
      "5  1.0    NaN  \n",
      "6  1.0  sleep  \n",
      "7  1.0    NaN  \n",
      "Loading 1003's data\n",
      "     ID                timestamp         x         y         z          HR  \\\n",
      "0  1003  2019-01-14 15:46:12.937  0.310316  0.436646  0.242333  109.613090   \n",
      "1  1003  2019-01-14 15:46:13.098  0.309846  0.433059  0.245624  109.613090   \n",
      "2  1003  2019-01-14 15:46:13.259  0.310880  0.432964  0.244489  109.613090   \n",
      "3  1003  2019-01-14 15:46:13.419  0.310128  0.432776  0.246305  109.613090   \n",
      "4  1003  2019-01-14 15:46:13.583  0.308623  0.435513  0.242333  109.613090   \n",
      "5  1003  2019-01-14 15:46:13.741  0.310222  0.437212  0.242447  109.613090   \n",
      "6  1003  2019-01-14 15:46:13.902  0.309940  0.437590  0.241312  109.613090   \n",
      "7  1003  2019-01-14 15:46:14.064  0.308999  0.435891  0.243241  108.660355   \n",
      "\n",
      "    AI  Label  \n",
      "0  1.0  stand  \n",
      "1  1.0    NaN  \n",
      "2  1.0    sit  \n",
      "3  1.0    NaN  \n",
      "4  1.0  stand  \n",
      "5  1.0    NaN  \n",
      "6  1.0  sleep  \n",
      "7  1.0    NaN  \n",
      "Loading 1004's data\n",
      "     ID                timestamp         x         y         z         HR  \\\n",
      "0  1004  2019-01-14 16:05:55.968  0.450811  0.698594  0.549334  65.810875   \n",
      "1  1004  2019-01-14 16:05:56.104  0.450483  0.691148  0.548861  64.419220   \n",
      "2  1004  2019-01-14 16:05:56.266  0.451030  0.694995  0.550122  64.419220   \n",
      "3  1004  2019-01-14 16:05:56.425  0.450264  0.696857  0.548388  64.419220   \n",
      "4  1004  2019-01-14 16:05:56.585  0.448732  0.695492  0.549807  64.419220   \n",
      "5  1004  2019-01-14 16:05:56.747  0.446544  0.695368  0.547758  64.419220   \n",
      "6  1004  2019-01-14 16:05:56.907  0.450811  0.693878  0.554851  64.419220   \n",
      "7  1004  2019-01-14 16:05:57.067  0.451905  0.694002  0.544921  64.419220   \n",
      "\n",
      "    AI  Label  \n",
      "0  1.0  stand  \n",
      "1  1.0    NaN  \n",
      "2  1.0    sit  \n",
      "3  1.0    NaN  \n",
      "4  1.0  stand  \n",
      "5  1.0    NaN  \n",
      "6  1.0  sleep  \n",
      "7  1.0    NaN  \n",
      "Loading 1005's data\n",
      "     ID                timestamp         x         y         z         HR  \\\n",
      "0  1005  2019-01-14 16:22:08.125  0.465816  0.586345  0.228269  77.318910   \n",
      "1  1005  2019-01-14 16:22:08.285  0.463691  0.587857  0.229407  77.318910   \n",
      "2  1005  2019-01-14 16:22:08.447  0.461424  0.586345  0.228952  77.318910   \n",
      "3  1005  2019-01-14 16:22:08.605  0.462558  0.584228  0.227130  77.228546   \n",
      "4  1005  2019-01-14 16:22:08.767  0.463691  0.586345  0.227814  77.228546   \n",
      "5  1005  2019-01-14 16:22:08.929  0.463974  0.589369  0.231229  77.228546   \n",
      "6  1005  2019-01-14 16:22:09.088  0.465250  0.585740  0.228497  77.228546   \n",
      "7  1005  2019-01-14 16:22:09.252  0.464683  0.584833  0.231457  77.228546   \n",
      "\n",
      "    AI  Label  \n",
      "0  1.0  stand  \n",
      "1  1.0    NaN  \n",
      "2  1.0  stand  \n",
      "3  1.0    NaN  \n",
      "4  1.0    sit  \n",
      "5  1.0    NaN  \n",
      "6  1.0  stand  \n",
      "7  1.0    NaN  \n",
      "Loading 1006's data\n",
      "     ID                timestamp         x         y         z          HR  \\\n",
      "0  1006  2019-01-14 16:36:30.983  0.516708  0.410653  0.244798  112.145020   \n",
      "1  1006  2019-01-14 16:36:31.144  0.501930  0.422444  0.246897  112.145020   \n",
      "2  1006  2019-01-14 16:36:31.303  0.492997  0.416960  0.232695  112.145020   \n",
      "3  1006  2019-01-14 16:36:31.463  0.522553  0.416137  0.227015  112.145020   \n",
      "4  1006  2019-01-14 16:36:31.624  0.521450  0.419428  0.221087  112.145020   \n",
      "5  1006  2019-01-14 16:36:31.784  0.526964  0.418514  0.232942  112.145020   \n",
      "6  1006  2019-01-14 16:36:31.947  0.504467  0.421621  0.248379  112.145020   \n",
      "7  1006  2019-01-14 16:36:32.106  0.468073  0.444450  0.270732  107.103455   \n",
      "\n",
      "    AI  Label  \n",
      "0  1.0  stand  \n",
      "1  1.0    NaN  \n",
      "2  1.0    sit  \n",
      "3  1.0    NaN  \n",
      "4  1.0  stand  \n",
      "5  1.0    NaN  \n",
      "6  1.0  sleep  \n",
      "7  1.0    NaN  \n",
      "Loading 1007's data\n",
      "     ID                timestamp         x         y         z         HR  \\\n",
      "0  1007  2019-01-14 16:56:30.016  0.287976  0.408082  0.373562  88.573654   \n",
      "1  1007  2019-01-14 16:56:30.177  0.292097  0.390515  0.375817  88.573654   \n",
      "2  1007  2019-01-14 16:56:30.335  0.283503  0.422886  0.373562  88.573654   \n",
      "3  1007  2019-01-14 16:56:30.496  0.293392  0.378142  0.363878  88.573654   \n",
      "4  1007  2019-01-14 16:56:30.656  0.289272  0.414600  0.378204  88.573654   \n",
      "5  1007  2019-01-14 16:56:30.817  0.291038  0.392725  0.377674  88.573654   \n",
      "6  1007  2019-01-14 16:56:30.978  0.288801  0.401563  0.373827  88.573654   \n",
      "7  1007  2019-01-14 16:56:31.138  0.282561  0.395818  0.369449  88.899510   \n",
      "\n",
      "    AI  Label  \n",
      "0  1.0  stand  \n",
      "1  1.0    NaN  \n",
      "2  1.0    sit  \n",
      "3  1.0    NaN  \n",
      "4  1.0  stand  \n",
      "5  1.0    NaN  \n",
      "6  1.0  sleep  \n",
      "7  1.0    NaN  \n",
      "Loading 1008's data\n",
      "     ID                timestamp         x         y         z        HR   AI  \\\n",
      "0  1008  2019-01-14 17:17:25.722  0.590187  0.516222  0.244771  82.04222  1.0   \n",
      "1  1008  2019-01-14 17:17:25.882  0.589560  0.508363  0.242176  81.85350  1.0   \n",
      "2  1008  2019-01-14 17:17:26.043  0.595203  0.523275  0.267148  81.85350  1.0   \n",
      "3  1008  2019-01-14 17:17:26.202  0.592486  0.514005  0.231474  81.85350  1.0   \n",
      "4  1008  2019-01-14 17:17:26.362  0.588306  0.509169  0.240879  81.85350  1.0   \n",
      "5  1008  2019-01-14 17:17:26.524  0.592486  0.512796  0.240555  81.85350  1.0   \n",
      "6  1008  2019-01-14 17:17:26.684  0.594158  0.510579  0.234068  81.85350  1.0   \n",
      "7  1008  2019-01-14 17:17:26.844  0.591441  0.510579  0.235690  81.85350  1.0   \n",
      "\n",
      "   Label  \n",
      "0  stand  \n",
      "1    NaN  \n",
      "2    sit  \n",
      "3    NaN  \n",
      "4  stand  \n",
      "5    NaN  \n",
      "6  sleep  \n",
      "7    NaN  \n",
      "Loading 1009's data\n",
      "     ID                timestamp         x         y         z         HR  \\\n",
      "0  1009  2019-02-08 16:37:19.423  0.548030  0.384379  0.211127  77.003204   \n",
      "1  1009  2019-02-08 16:37:19.584  0.546719  0.383567  0.210499  77.003204   \n",
      "2  1009  2019-02-08 16:37:19.744  0.548795  0.380184  0.210917  77.003204   \n",
      "3  1009  2019-02-08 16:37:19.903  0.548686  0.382755  0.206940  77.003204   \n",
      "4  1009  2019-02-08 16:37:20.065  0.546609  0.380861  0.211755  77.003204   \n",
      "5  1009  2019-02-08 16:37:20.224  0.545407  0.388303  0.204637  77.003204   \n",
      "6  1009  2019-02-08 16:37:20.385  0.547265  0.385732  0.205893  77.003204   \n",
      "7  1009  2019-02-08 16:37:20.545  0.544970  0.388979  0.206312  76.441190   \n",
      "\n",
      "    AI  Label  \n",
      "0  1.0  stand  \n",
      "1  1.0    NaN  \n",
      "2  1.0    sit  \n",
      "3  1.0    NaN  \n",
      "4  1.0  stand  \n",
      "5  1.0    NaN  \n",
      "6  1.0  sleep  \n",
      "7  1.0    NaN  \n",
      "Loading 1010's data\n",
      "     ID                timestamp         x         y         z         HR  \\\n",
      "0  1010  2019-02-09 17:25:35.065  0.526175  0.573747  0.335509  71.977875   \n",
      "1  1010  2019-02-09 17:25:35.226  0.525215  0.573747  0.335627  71.977875   \n",
      "2  1010  2019-02-09 17:25:35.387  0.525575  0.572894  0.333501  71.977875   \n",
      "3  1010  2019-02-09 17:25:35.545  0.524975  0.576303  0.335982  71.977875   \n",
      "4  1010  2019-02-09 17:25:35.708  0.525815  0.573179  0.334210  70.109726   \n",
      "5  1010  2019-02-09 17:25:35.868  0.525815  0.571048  0.334800  70.109726   \n",
      "6  1010  2019-02-09 17:25:36.029  0.525935  0.575167  0.333146  70.109726   \n",
      "7  1010  2019-02-09 17:25:36.187  0.520535  0.568918  0.335155  70.109726   \n",
      "\n",
      "    AI  Label  \n",
      "0  1.0  stand  \n",
      "1  1.0    NaN  \n",
      "2  1.0    sit  \n",
      "3  1.0    NaN  \n",
      "4  1.0  stand  \n",
      "5  1.0    NaN  \n",
      "6  1.0  sleep  \n",
      "7  1.0    NaN  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1011's data\n",
      "     ID                timestamp         x         y         z        HR   AI  \\\n",
      "0  1011  2019-02-10 12:04:34.754  0.429707  0.505692  0.382619  85.48731  1.0   \n",
      "1  1011  2019-02-10 12:04:34.916  0.427799  0.507134  0.383295  85.56079  1.0   \n",
      "2  1011  2019-02-10 12:04:35.076  0.428944  0.506516  0.371813  85.56079  1.0   \n",
      "3  1011  2019-02-10 12:04:35.238  0.427545  0.504662  0.369787  85.56079  1.0   \n",
      "4  1011  2019-02-10 12:04:35.397  0.427799  0.509813  0.371588  85.56079  1.0   \n",
      "5  1011  2019-02-10 12:04:35.558  0.412539  0.503013  0.359881  85.56079  1.0   \n",
      "6  1011  2019-02-10 12:04:35.718  0.415973  0.505280  0.311701  85.56079  1.0   \n",
      "7  1011  2019-02-10 12:04:35.879  0.421568  0.510225  0.298024  85.56079  1.0   \n",
      "\n",
      "   Label  \n",
      "0  stand  \n",
      "1    NaN  \n",
      "2    sit  \n",
      "3    NaN  \n",
      "4  stand  \n",
      "5    NaN  \n",
      "6  sleep  \n",
      "7    NaN  \n",
      "Loading 1012's data\n",
      "     ID                timestamp         x         y         z        HR   AI  \\\n",
      "0  1012  2019-02-10 12:18:17.088  0.330780  0.692930  0.315403  71.52065  1.0   \n",
      "1  1012  2019-02-10 12:18:17.246  0.399746  0.665595  0.243684  71.52065  1.0   \n",
      "2  1012   2019-02-10 12:18:17.41  0.396149  0.725692  0.229247  71.52065  1.0   \n",
      "3  1012  2019-02-10 12:18:17.568  0.394164  0.726898  0.210909  71.52065  1.0   \n",
      "4  1012  2019-02-10 12:18:17.729  0.405948  0.713030  0.201595  71.52065  1.0   \n",
      "5  1012   2019-02-10 12:18:17.89  0.393544  0.714436  0.213005  71.52065  1.0   \n",
      "6  1012  2019-02-10 12:18:18.052  0.389823  0.712025  0.212074  71.52065  1.0   \n",
      "7  1012  2019-02-10 12:18:18.211  0.394660  0.714436  0.205786  67.45801  1.0   \n",
      "\n",
      "   Label  \n",
      "0  stand  \n",
      "1    NaN  \n",
      "2    sit  \n",
      "3    NaN  \n",
      "4  stand  \n",
      "5    NaN  \n",
      "6  sleep  \n",
      "7    NaN  \n",
      "Loading 1013's data\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-5f6a5296342d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_all_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_subjects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-a684f6dd558f>\u001b[0m in \u001b[0;36mload_all_data\u001b[0;34m(all_subjects)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading {0}'s data\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdf_timer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdf_filt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-348de18165b6>\u001b[0m in \u001b[0;36mload_timer\u001b[0;34m(subject_id)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtimer_filt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimer_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mstart_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer_filt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mend_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer_filt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimer_filt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1911\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1913\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no slices here, handle elsewhere'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3583\u001b[0m                                                       drop_level=drop_level)\n\u001b[1;32m   3584\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3585\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3587\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "load_all_data(all_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
