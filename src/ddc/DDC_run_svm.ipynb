{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7KG93zTnlu0"
   },
   "source": [
    "# Import Core Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4AvIBQQQMGyA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from os import listdir, walk\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Im12HZ4kMGyQ"
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],

   "source": [
    "%run load_dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects = []\n",
    "\n",
    "for i in range(1013,1015):\n",
    "    all_subjects.append(str(i))\n",
    "\n",
    "for i in range(3001,3007):\n",
    "    all_subjects.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1013's data\n",
      "    sid raw_label                timestamp  duration  label\n",
      "0  1001       ยืน  2562-01-14 14:52:31.027  00:00:30    NaN\n",
      "1  1001      นั่ง  2562-01-14 14:53:07.042  00:00:30    NaN\n",
      "2  1001       ยืน  2562-01-14 14:53:39.401  00:00:30    NaN\n",
      "3  1001   ไม่ระบุ  2562-01-14 14:54:44.531  00:00:02    NaN\n",
      "4  1001       นอน  2562-01-14 14:55:14.564  00:00:30    NaN\n",
      "Loading 1014's data\n",
      "    sid raw_label                timestamp  duration  label\n",
      "0  1014     stand  2019-03-01 14:42:41.337  00:00:30    NaN\n",
      "1  1014       sit  2019-03-01 14:43:14.660  00:00:30    NaN\n",
      "2  1014     stand  2019-03-01 14:43:48.112  00:00:30    NaN\n",
      "3  1014     sleep  2019-03-01 14:44:26.981  00:00:31    NaN\n",
      "4  1014       sit  2019-03-01 14:45:04.234  00:00:30    NaN\n",
      "Loading 3001's data\n",
      "    sid raw_label                timestamp  duration  label\n",
      "0  3001     stand  2019-03-05 10:03:24.582  00:00:31    NaN\n",
      "1  3001       sit  2019-03-05 10:04:10.264  00:00:30    NaN\n",
      "2  3001     stand  2019-03-05 10:04:54.583  00:00:30    NaN\n",
      "3  3001     sleep  2019-03-05 10:05:54.767  00:00:30    NaN\n",
      "4  3001       sit  2019-03-05 10:06:39.601  00:00:30    NaN\n",
      "Loading 3002's data\n",
      "    sid raw_label                timestamp  duration  label\n",
      "0  3001     stand  2019-03-05 10:03:24.582  00:00:31    NaN\n",
      "1  3001       sit  2019-03-05 10:04:10.264  00:00:30    NaN\n",
      "2  3001     stand  2019-03-05 10:04:54.583  00:00:30    NaN\n",
      "3  3001     sleep  2019-03-05 10:05:54.767  00:00:30    NaN\n",
      "4  3001       sit  2019-03-05 10:06:39.601  00:00:30    NaN\n",
      "Loading 3003's data\n",
      "    sid raw_label                timestamp  duration  label\n",
      "0  3001     stand  2019-03-05 10:03:24.582  00:00:31    NaN\n",
      "1  3001       sit  2019-03-05 10:04:10.264  00:00:30    NaN\n",
      "2  3001     stand  2019-03-05 10:04:54.583  00:00:30    NaN\n",
      "3  3001     sleep  2019-03-05 10:05:54.767  00:00:30    NaN\n",
      "4  3001       sit  2019-03-05 10:06:39.601  00:00:30    NaN\n",
      "Loading 3004's data\n",
      "    sid raw_label                timestamp  duration  label\n",
      "0  3001     stand  2019-03-05 10:03:24.582  00:00:31    NaN\n",
      "1  3001       sit  2019-03-05 10:04:10.264  00:00:30    NaN\n",
      "2  3001     stand  2019-03-05 10:04:54.583  00:00:30    NaN\n",
      "3  3001     sleep  2019-03-05 10:05:54.767  00:00:30    NaN\n",
      "4  3001       sit  2019-03-05 10:06:39.601  00:00:30    NaN\n",
      "Loading 3005's data\n",
      "    sid raw_label                timestamp  duration  label\n",
      "0  3001     stand  2019-03-05 10:03:24.582  00:00:31    NaN\n",
      "1  3001       sit  2019-03-05 10:04:10.264  00:00:30    NaN\n",
      "2  3001     stand  2019-03-05 10:04:54.583  00:00:30    NaN\n",
      "3  3001     sleep  2019-03-05 10:05:54.767  00:00:30    NaN\n",
      "4  3001       sit  2019-03-05 10:06:39.601  00:00:30    NaN\n",
      "Loading 3006's data\n",
      "    sid raw_label                timestamp  duration  label\n",
      "0  1001       ยืน  2562-01-14 14:52:31.027  00:00:30    NaN\n",
      "1  1001      นั่ง  2562-01-14 14:53:07.042  00:00:30    NaN\n",
      "2  1001       ยืน  2562-01-14 14:53:39.401  00:00:30    NaN\n",
      "3  1001   ไม่ระบุ  2562-01-14 14:54:44.531  00:00:02    NaN\n",
      "4  1001       นอน  2562-01-14 14:55:14.564  00:00:30    NaN\n",
      "Finished loading\n"
     ]
    }
   ],
   "source": [
    "X_all, y_all, subj_all, ts_all, hr_all = load_all_data(all_subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wyuXI7owzjG4"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotJSONError",
     "evalue": "Notebook does not appear to be JSON: '{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"m...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nbformat/reader.py\u001b[0m in \u001b[0;36mparse_json\u001b[0;34m(s, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mnb_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 664 column 1 (char 17723)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotJSONError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mget_cells\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2767\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.ipynb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2768\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0mnbformat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2769\u001b[0;31m                 \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2770\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2771\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nbformat/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(fp, as_version, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpy3compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0municode_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nbformat/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(fp, as_version, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nbformat/__init__.py\u001b[0m in \u001b[0;36mreads\u001b[0;34m(s, as_version, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnotebook\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwas\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mas_version\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNO_CONVERT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nbformat/reader.py\u001b[0m in \u001b[0;36mreads\u001b[0;34m(s, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNBFormatError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mnb_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmajor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mversions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nbformat/reader.py\u001b[0m in \u001b[0;36mparse_json\u001b[0;34m(s, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Limit the error message to 80 characters.  Display whatever JSON will fit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotJSONError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Notebook does not appear to be JSON: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m77\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnb_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotJSONError\u001b[0m: Notebook does not appear to be JSON: '{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"m..."
     ]
    }
   ],
   "source": [
    "%run preprocessing.ipynb\n",
    "# includes wavelet denoising, normalization, PCA, LDA, SVD, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1e1804f40cb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_all' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_all.shape, y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ac3q3J-hXiY"
   },
   "source": [
    "# Group Data by Label and Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_list)\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_label_list = [0,1,2,3]\n",
    "new_label_dict = {\n",
    "    0: 'sit',\n",
    "    1: 'sleep',\n",
    "    2: 'stand',\n",
    "    3: 'walk'\n",
    "}\n",
    "\n",
    "colors = ['r','g','b','navy','turquoise','darkorange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group X_all and y_all from load_dataset.ipynb by labels\n",
    "X_label, y_label = label_grouping(X_all, y_all, subj_all, new_label_list)\n",
    "\n",
    "# normalize X_label\n",
    "X_norm = normalize_data(X_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Plot for each Activity and Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_all_label(X_label, y_all, new_label_list, new_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Roll, Pitch, Yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll, pitch, yaw = calc_rpy(X_all, subject_id, colors)\n",
    "rpy = np.array([roll, pitch, yaw]).transpose()\n",
    "\n",
    "print(rpy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply PCA and LDA to X_norm and rpy\n",
    "X_pca, pca = apply_pca(X_all, y_all, label_list)\n",
    "rpy_pca, pca_rpy = apply_pca(rpy, y_all, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape Data (Pure Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label-separated X and y\n",
    "X_svm, y_svm = prepare_pure_label(X_pca, y_all, subj_all, new_label_list)\n",
    "y_svm = y_svm.reshape((y_svm.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_svm.shape, y_svm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape Data (Impure Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_impure, y_impure = prepare_impure_label(X_pca, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_impure.shape, y_impure.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_svm, y_svm, test_size=0.2, random_state=42)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_impure, y_impure, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_tr.shape)\n",
    "print(X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm_classifier(X_train, y_train)\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model/svm_model.pkl'\n",
    "pickle.dump(svm_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_2 = svm_classifier(X_tr, y_tr)\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_2 = svm_model_2.predict(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run eval_score.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['sit','sleep','stand','walk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred_svm)\n",
    "print(acc)\n",
    "\n",
    "show_conf_matrix(y_test, y_pred_svm, LABELS)\n",
    "show_clf_report(y_test, y_pred_svm, LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_te, y_pred_svm_2)\n",
    "print(acc)\n",
    "\n",
    "show_conf_matrix(y_te, y_pred_svm_2, LABELS)\n",
    "show_clf_report(y_te, y_pred_svm_2, LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walk Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run classifier_alg.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify walking\n",
    "walk = calc_walk(X_all)\n",
    "walk_its = intersection_walk(walk)\n",
    "walk_pred_p = calc_walk_periods(walk_its)\n",
    "\n",
    "# walk_stairs_exact_p = get_exact_walk_stairs(y_all)\n",
    "walk_exact_p = get_exact_walk(y_all)\n",
    "    \n",
    "walk_pred = binarize_walk_prd(walk_pred_p, y_all)\n",
    "# walk_stairs_exact = binarize_walk_prd(walk_stairs_exact_p, y_all)\n",
    "walk_exact = binarize_walk_prd(walk_exact_p, y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk Algorithm Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_lbl = ['NaN','walk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(walk_exact, walk_pred)\n",
    "print(acc)\n",
    "\n",
    "show_conf_matrix(walk_exact, walk_pred, walk_lbl)\n",
    "show_clf_report(walk_exact, walk_pred, walk_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine SVM and Walk Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_new = combine(X_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred_new)\n",
    "print(acc)\n",
    "\n",
    "show_conf_matrix(y_test, y_pred_new, LABELS)\n",
    "show_clf_report(y_test, y_pred_new, LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model with Some Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run test_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model/svm_model.pkl'\n",
    "\n",
    "model = pickle.load(open(filename,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects = [str(i) for i in range(1001,1009)]\n",
    "all_subjects.append('2001')\n",
    "all_subjects.append('2002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "call_functions(all_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_subjects = [str(i) for i in range(3001,3006)]\n",
    "\n",
    "call_functions(all_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = '3004'\n",
    "df_sid = load_actual_timer(s)\n",
    "df_test = load_data(s, df_sid)\n",
    "\n",
    "X_vis_imp, ts_list_imp = preprocess_data(df_test, pca)\n",
    "df_y = predict(X_vis_imp, ts_list_imp)\n",
    "\n",
    "df_test, df_y = prepare_actual_lb(df_test, df_y, df_sid)\n",
    "\n",
    "actual_periods = get_actual_periods(df_test)\n",
    "pred_periods = get_predicted_periods(df_y)\n",
    "pp_all_run = postprocess_predicted(pred_periods, df_y)\n",
    "\n",
    "df_y['y_pred'] = pd.Series(pp_all_run)\n",
    "pp_periods = get_predicted_periods(df_y)\n",
    "plot_highlighted(s, df_test, pp_periods, actual_periods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(s)\n",
    "print(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_period = []\n",
    "period_list = [[] for i in range(len(LABELS))]\n",
    "\n",
    "first = 0\n",
    "keep = 0\n",
    "\n",
    "for i in range(len(df_y)):\n",
    "    if(calc_sec(df_y.loc[i]['timestamp'].split(' ')[1])>=calc_sec(df_sid.loc[0]['timestamp'].split(' ')[1]) and\n",
    "       calc_sec(df_y.loc[i]['timestamp'].split(' ')[1])<=calc_sec(df_sid.loc[len(df_sid)-1]['timestamp'].split(' ')[1])):\n",
    "        \n",
    "        keep_lb = df_y.loc[keep]['y_pred']\n",
    "\n",
    "        if(keep_lb!=df_y.loc[i]['y_pred']):\n",
    "            label_period.append([df_y.loc[keep]['timestamp'], df_y.loc[i-1]['timestamp'], \n",
    "                                 df_y.loc[i-1]['y_pred']])\n",
    "\n",
    "            period_list[df_y.loc[i-1]['y_pred']].append([df_y.loc[keep]['timestamp'], df_y.loc[i-1]['timestamp']])\n",
    "\n",
    "            keep = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = ['sit', 'sleep', 'stand', 'walk']\n",
    "headers = ['start', 'end', 'pred']\n",
    "\n",
    "t = PrettyTable(headers)\n",
    "\n",
    "for row in label_period:\n",
    "#     if(calc_sec(row[1].split(' ')[1])-calc_sec(row[0].split(' ')[1])>1):\n",
    "    t.add_row([row[0], row[1], labels_list[row[2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(label_period))\n",
    "\n",
    "label_cnt_list = [0 for i in range(len(labels_list))]\n",
    "for lb_p in label_period:\n",
    "    label_i = lb_p[2]\n",
    "    \n",
    "    label_cnt_list[label_i] += 1\n",
    "\n",
    "activity_changes = []\n",
    "for i in range(len(labels_list)):\n",
    "    activity_changes.append([labels_list[i], label_cnt_list[i]])\n",
    "    \n",
    "print(activity_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Label', 'Activities Count']\n",
    "tabl_act_chng = PrettyTable(headers)\n",
    "\n",
    "for ac in activity_changes:\n",
    "    tabl_act_chng.add_row([ac[0], ac[1]])\n",
    "    \n",
    "tabl_act_chng.add_row(['', ''])\n",
    "tabl_act_chng.add_row(['total changes', len(label_period)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(tabl_act_chng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Inactive AC (ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Label', 'Activities Count']\n",
    "tabl_act = PrettyTable(headers)\n",
    "inactive_table = []\n",
    "active_table = []\n",
    "\n",
    "sum = 0\n",
    "sum_2 = 0\n",
    "for ac in activity_changes:\n",
    "    if(ac[0] == 'sit' or ac[0] == 'sleep'):\n",
    "        sum += ac[1]\n",
    "    else :\n",
    "        sum_2 += ac[1]\n",
    "\n",
    "tabl_act.add_row(['Inactive', sum])\n",
    "tabl_act.add_row(['Active', sum_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabl_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Time to String Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time_to_string(sec):\n",
    "    minute = math.floor(sec/60)\n",
    "    sec = int(sec%60)\n",
    "\n",
    "    time_string = str(minute) + ':' + str(sec)\n",
    "    if(sec<10):\n",
    "        time_string = str(minute) + ':0' + str(sec)\n",
    "    \n",
    "    return time_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicted Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_secs = []\n",
    "for i in range(len(period_list)):    \n",
    "    secs = 0\n",
    "    for p_i in period_list[i]:\n",
    "        sec = calc_sec(p_i[1].split(' ')[1]) - calc_sec(p_i[0].split(' ')[1])\n",
    "        secs += sec\n",
    "    \n",
    "    secs = round(secs, 3)\n",
    "    total_secs.append(secs)\n",
    "    \n",
    "percent_secs = [round(t/np.sum(total_secs)*100, 3) for t in total_secs]\n",
    "\n",
    "tb = PrettyTable(['Label', 'Minutes', 'Percentage', 'Activity Count'])\n",
    "\n",
    "for i in range(len(LABELS)):\n",
    "    tb.add_row([labels_list[i], convert_time_to_string(total_secs[i]), percent_secs[i], label_cnt_list[i]])\n",
    "\n",
    "tb.add_row(['', '', '',''])\n",
    "tb.add_row(['total', convert_time_to_string(round(np.sum(total_secs), 3)), \n",
    "            round(np.sum(percent_secs), 3), len(label_period)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lb = df_sid.groupby('label')\n",
    "\n",
    "dura_dict = {}\n",
    "for lb in labels_list:\n",
    "    dura_dict[lb] = 0\n",
    "\n",
    "idx = list(df_sid.index)\n",
    "for i in range(len(labels_list)):\n",
    "    lb = labels_list[i]\n",
    "    df_temp = df_lb.get_group(lb)\n",
    "    df_temp = df_temp.reset_index(drop=True)\n",
    "        \n",
    "    if(lb=='downstairs' or lb=='upstairs'):\n",
    "        lb = 'walk'\n",
    "    \n",
    "    for j in range(len(df_temp)):\n",
    "        dura_dict[lb] += calc_sec(df_temp.loc[j]['duration'])\n",
    "        \n",
    "total_dura = np.sum([dura_dict[lb] for lb in labels_list])\n",
    "\n",
    "percent_list = []\n",
    "        \n",
    "tabl = PrettyTable(['Label', 'Minutes', 'Percentage'])\n",
    "for lb in labels_list:\n",
    "    percent = round(dura_dict[lb]/total_dura*100, 3)\n",
    "    tabl.add_row([lb, convert_time_to_string(dura_dict[lb]), round(dura_dict[lb]/total_dura*100, 3)])\n",
    "    \n",
    "    percent_list.append(percent)\n",
    "    \n",
    "tabl.add_row(['', '', ''])    \n",
    "tabl.add_row(['total', convert_time_to_string(total_dura), round(np.sum(percent_list), 3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Durations Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Prediction')\n",
    "print(tb)\n",
    "\n",
    "print('Actual')\n",
    "print(tabl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar Chart for Every 5 Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_idx = 0\n",
    "f_idx = 1\n",
    "lb_idx = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Each 5 Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fivemin = 60*5\n",
    "new_label_period = []\n",
    "\n",
    "start_time = calc_sec(label_period[0][s_idx].split(' ')[1])\n",
    "finish_time = calc_sec(label_period[-1][f_idx].split(' ')[1])\n",
    "\n",
    "floor_start = start_time - (start_time%fivemin)\n",
    "ceil_finish = finish_time - (finish_time%fivemin) + fivemin\n",
    "\n",
    "print(calc_ts(floor_start), calc_ts(ceil_finish))\n",
    "\n",
    "tm_s = floor_start\n",
    "tm_f = floor_start + fivemin\n",
    "date = label_period[0][s_idx].split(' ')[0]\n",
    "\n",
    "for prd in label_period:\n",
    "    if(calc_sec(prd[f_idx].split(' ')[1])>=tm_f):\n",
    "        new_prd = [prd[s_idx], date + ' ' + calc_ts(tm_f), prd[lb_idx]]\n",
    "        new_label_period.append(new_prd)\n",
    "        \n",
    "        tm_s += fivemin\n",
    "        tm_f += fivemin\n",
    "    else:\n",
    "        new_label_period.append(prd)\n",
    "                \n",
    "    if(calc_sec(prd[s_idx].split(' ')[1])<tm_s):\n",
    "        new_prd = [date + ' ' + calc_ts(tm_s), prd[f_idx], prd[lb_idx]]\n",
    "        new_label_period.append(new_prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_periods_label = []\n",
    "\n",
    "for t_i in range(int(floor_start), int(ceil_finish), fivemin):\n",
    "    period_lb = [0 for i in range(len(LABELS))]\n",
    "    for prd in new_label_period:\n",
    "        if(calc_sec(prd[s_idx].split(' ')[1])>=t_i and calc_sec(prd[f_idx].split(' ')[1])<=t_i+fivemin):\n",
    "            period_lb[prd[lb_idx]] += calc_sec(prd[f_idx].split(' ')[1])-calc_sec(prd[s_idx].split(' ')[1])\n",
    "            period_lb[prd[lb_idx]] = round(period_lb[prd[lb_idx]], 3)\n",
    "            \n",
    "    all_periods_label.append(period_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame(all_periods_label, columns=labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Bar Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = list(range(len(df_all['sit'])))\n",
    "width = 0.2\n",
    "colors = ['crimson','gold','lime','dodgerblue']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "for i in range(len(LABELS)):\n",
    "    plt.bar([p + i*width for p in pos],\n",
    "            df_all[labels_list[i]],\n",
    "            width,\n",
    "            alpha=0.5,\n",
    "            color=colors[i],\n",
    "            label=labels_list[i])\n",
    "    \n",
    "ax.set_xticks([p + 1.5 * width for p in pos])\n",
    "\n",
    "xtick_labels = [calc_ts(floor_start + i*fivemin) + '-' + calc_ts(floor_start + (i+1)*fivemin)\n",
    "                for i in range(len(df_all))]\n",
    "ax.set_xticklabels(xtick_labels)\n",
    "\n",
    "ax.set_ylabel('Time (sec)')\n",
    "\n",
    "plt.xlim(min(pos)-width, max(pos)+width*4)\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Activity Summary for Subject ID: ' + s)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DDC_run.ipynb",
   "provenance": [
    {
     "file_id": "1uW9RzCQha3RZ_wzM_gLxhAN7ytclHWHC",
     "timestamp": 1548220076491
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
