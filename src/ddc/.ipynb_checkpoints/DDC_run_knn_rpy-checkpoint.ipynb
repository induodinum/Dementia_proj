{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7KG93zTnlu0"
   },
   "source": [
    "# Import Core Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4AvIBQQQMGyA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from os import listdir, walk\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detect_peaks import detect_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Im12HZ4kMGyQ"
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run load_dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_range = np.hstack((np.arange(1001,1013),np.arange(2002,2003)))\n",
    "\n",
    "all_subjects = [str(i) for i in subj_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_range = np.hstack((np.arange(2001,2002),np.arange(3001,3006)))\n",
    "\n",
    "all_patients = [str(i) for i in subj_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1001', '1002', '1003', '1004', '1005', '1006', '1007', '1008', '1009', '1010', '1011', '1012', '2002']\n",
      "['2001', '3001', '3002', '3003', '3004', '3005']\n"
     ]
    }
   ],
   "source": [
    "print(all_subjects)\n",
    "print(all_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1001's data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fifamd\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1002's data\n",
      "Loading 1003's data\n",
      "Loading 1004's data\n",
      "Loading 1005's data\n",
      "Loading 1006's data\n",
      "Loading 1007's data\n",
      "Loading 1008's data\n",
      "Loading 1009's data\n",
      "Loading 1010's data\n",
      "Loading 1011's data\n",
      "Loading 1012's data\n",
      "Loading 2002's data\n",
      "Finished loading\n"
     ]
    }
   ],
   "source": [
    "X_all, y_all, subj_all = load_all_data(all_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2001's data\n",
      "Loading 3001's data\n",
      "Loading 3002's data\n",
      "Loading 3003's data\n",
      "Loading 3004's data\n",
      "Loading 3005's data\n",
      "Finished loading\n"
     ]
    }
   ],
   "source": [
    "X_all_p, y_all_p, subj_all_p = load_all_data(all_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10998, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all_p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wyuXI7owzjG4"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26716, 3) (26716,)\n"
     ]
    }
   ],
   "source": [
    "print(X_all.shape, y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.99275204e-01, -9.03566837e-01, -6.10765714e-04],\n",
       "       [-3.04649949e-01, -9.05032653e-01,  4.64181969e-03],\n",
       "       [-3.01229663e-01, -9.01612347e-01,  2.68736939e-03],\n",
       "       ...,\n",
       "       [-8.85488163e-01,  1.68082724e-01,  2.51024714e-01],\n",
       "       [-9.08941531e-01,  2.15478163e-01,  3.25293837e-01],\n",
       "       [-9.29463367e-01, -8.44078224e-02,  2.32946041e-01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ac3q3J-hXiY"
   },
   "source": [
    "# Group Data by Label and Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_label_list = [0,1,2,3]\n",
    "new_label_dict = {\n",
    "    0: 'sit',\n",
    "    1: 'sleep',\n",
    "    2: 'stand',\n",
    "    3: 'walk'\n",
    "}\n",
    "\n",
    "colors = ['r','g','b','navy','turquoise','darkorange']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Plot for each Activity and Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_all_label(X_label, y_all, new_label_list, new_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Roll, Pitch, Yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26716, 3) (26716,)\n"
     ]
    }
   ],
   "source": [
    "roll, pitch, yaw = calc_rpy(X_all, colors)\n",
    "rpy = np.array([roll, pitch, yaw]).transpose()\n",
    "\n",
    "print(rpy.shape, y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10998, 3) (10998,)\n"
     ]
    }
   ],
   "source": [
    "roll, pitch, yaw = calc_rpy(X_all_p, colors)\n",
    "rpy_p = np.array([roll, pitch, yaw]).transpose()\n",
    "\n",
    "print(rpy_p.shape, y_all_p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LABELS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-53aeca62619b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# apply PCA to X_all and rpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_pca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLABELS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrpy_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_pca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrpy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLABELS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LABELS' is not defined"
     ]
    }
   ],
   "source": [
    "# apply PCA to X_all and rpy\n",
    "X_pca, pca = apply_pca(X_all, y_all,label_list)\n",
    "rpy_pca, pca = apply_pca(rpy, y_all, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-5d079ce32f89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# apply PCA and LDA to X_all and rpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_pca_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_pca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_all_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_all_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrpy_pca_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_pca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrpy_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_all_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'label_list' is not defined"
     ]
    }
   ],
   "source": [
    "# apply PCA and LDA to X_all and rpy\n",
    "X_pca_p, pca_p = apply_pca(X_all_p, y_all_p, label_list)\n",
    "rpy_pca_p, pca_p = apply_pca(rpy_p, y_all_p, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape Data (Pure Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rpy_pca_p.shape, y_all_p.shape, subj_all_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get label-separated X and y\n",
    "X_pure, y_pure = prepare_pure_label(rpy_pca_p, y_all_p, subj_all_p, all_patients, new_label_list)\n",
    "y_pure = y_pure.reshape((y_pure.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_pure.shape, y_pure.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape Data (Impure Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_impure, y_impure = prepare_impure_label(rpy_pca_p, y_all_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_impure.shape, y_impure.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pure, y_pure, test_size=0.2, random_state=42)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_impure, y_impure, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_tr.shape)\n",
    "print(X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find proper thresholds of walk activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dict = {\n",
    "    'id': subj_all_p,\n",
    "    'x': [X_i[0] for X_i in X_all_p],\n",
    "    'y': [X_i[1] for X_i in X_all_p],\n",
    "    'z': [X_i[2] for X_i in X_all_p],\n",
    "    'x_pca': [X_i_pca[0] for X_i_pca in X_pca_p],\n",
    "    'y_pca': [X_i_pca[1] for X_i_pca in X_pca_p],\n",
    "    'z_pca': [X_i_pca[2] for X_i_pca in X_pca_p],\n",
    "    'roll': [rpy_pca_i[0] for rpy_pca_i in rpy_pca_p],\n",
    "    'pitch': [rpy_pca_i[1] for rpy_pca_i in rpy_pca_p],\n",
    "    'yaw': [rpy_pca_i[2] for rpy_pca_i in rpy_pca_p],\n",
    "    'label': y_all_p\n",
    "}\n",
    "\n",
    "df_rpy = pd.DataFrame(X_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_walk = df_rpy[df_rpy['label']==label_dict['walk']]\n",
    "df_walk = df_walk.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonwalk = df_rpy[df_rpy['label']!=label_dict['walk']]\n",
    "df_nonwalk = df_nonwalk.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = ['x_pca', 'y_pca', 'z_pca']\n",
    "\n",
    "df_rpy[cols].plot(figsize=(20,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['x_pca', 'y_pca', 'z_pca']\n",
    "\n",
    "for c in cols:\n",
    "    f, ax = plt.subplots()\n",
    "    df_walk[c].plot(figsize=(20,6), ax=ax)\n",
    "    ax.legend(c)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['x_pca', 'y_pca', 'z_pca']\n",
    "\n",
    "for c in cols:\n",
    "    f, ax = plt.subplots()\n",
    "    df_nonwalk[c].plot(figsize=(20,6), ax=ax)\n",
    "    ax.legend(c)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['x_pca', 'y_pca', 'z_pca']\n",
    "all_avg_diff = [[],[],[]]\n",
    "\n",
    "for subj_i in all_patients:\n",
    "    df_walk_i = df_walk[df_walk['id']==subj_i]\n",
    "    df_walk_i = df_walk_i.reset_index(drop=True)\n",
    "    \n",
    "    print(subj_i)\n",
    "    \n",
    "    for i in range(len(cols)):\n",
    "        c = cols[i]\n",
    "        \n",
    "        peak_idx = detect_peaks(df_walk_i[c], show=True)    \n",
    "        valley_idx = detect_peaks(df_walk_i[c], valley=True, show=True)\n",
    "\n",
    "        peak_point = [df_walk_i.loc[i, c] for i in peak_idx]    \n",
    "        valley_point = [df_walk_i.loc[i, c] for i in valley_idx]\n",
    "\n",
    "        min_length = min(len(peak_idx), len(valley_idx))\n",
    "\n",
    "        diff_peak_valley = [np.abs(peak_point[i] - valley_point[i]) for i in range(min_length)]\n",
    "        avg_diff_pv = np.mean(diff_peak_valley)\n",
    "\n",
    "#         print(diff_peak_valley)\n",
    "        print(c, avg_diff_pv)\n",
    "        \n",
    "        all_avg_diff[i].append(avg_diff_pv)\n",
    "        \n",
    "all_avg_diff = np.array(all_avg_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['x_pca', 'y_pca', 'z_pca']\n",
    "all_avg_diff_nw = [[],[],[]]\n",
    "\n",
    "for subj_i in all_patients:\n",
    "    df_nonwalk_i = df_nonwalk[df_nonwalk['id']==subj_i]\n",
    "    df_nonwalk_i = df_nonwalk_i.reset_index(drop=True)\n",
    "    \n",
    "    print(subj_i)\n",
    "    \n",
    "    for i in range(len(cols)):\n",
    "        c = cols[i]\n",
    "        \n",
    "        peak_idx = detect_peaks(df_nonwalk_i[c], show=True)    \n",
    "        valley_idx = detect_peaks(df_nonwalk_i[c], valley=True, show=True)\n",
    "\n",
    "        peak_point = [df_nonwalk_i.loc[i, c] for i in peak_idx]    \n",
    "        valley_point = [df_nonwalk_i.loc[i, c] for i in valley_idx]\n",
    "\n",
    "        min_length = min(len(peak_idx), len(valley_idx)) - 1\n",
    "\n",
    "        diff_peak_valley = [np.abs(peak_point[i] - valley_point[i]) for i in range(min_length)]\n",
    "        avg_diff_pv = np.mean(diff_peak_valley)\n",
    "\n",
    "    #     print(diff_peak_valley)\n",
    "        print(c, avg_diff_pv)\n",
    "        \n",
    "        all_avg_diff_nw[i].append(avg_diff_pv)\n",
    "        \n",
    "all_avg_diff_nw = np.array(all_avg_diff_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aad_t = all_avg_diff.transpose()\n",
    "\n",
    "print('walking for patients')\n",
    "for i in range(len(aad_t)):\n",
    "    print(all_patients[i], aad_t[i])\n",
    "    \n",
    "aad_nw_t = all_avg_diff_nw.transpose()\n",
    "\n",
    "print()\n",
    "print('non-walking for patients')\n",
    "for i in range(len(aad_nw_t)):\n",
    "    print(all_patients[i], aad_nw_t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "three_sec = 20   # 3 sec/0.16 sec = 18.75 time point\n",
    "one_sec = 6      # 1 sec/0.16 sec = 6.25 time point\n",
    "\n",
    "cols = ['x_pca', 'y_pca', 'z_pca']\n",
    "threshold = [0.15, 0.13, 0.11]\n",
    "\n",
    "exceed_thres = [[],[],[]]\n",
    "\n",
    "for cl in range(len(cols)):\n",
    "    c = cols[cl]\n",
    "    \n",
    "    for i in range(0, len(df_walk)-three_sec, one_sec):\n",
    "        df_walk_i = [df_walk.loc[j, c] for j in range(i,i+three_sec)]\n",
    "        \n",
    "        peak_idx = detect_peaks(df_walk_i)    \n",
    "        valley_idx = detect_peaks(df_walk_i, valley=True)\n",
    "\n",
    "        peak_point = [df_walk_i[j] for j in peak_idx]    \n",
    "        valley_point = [df_walk_i[j] for j in valley_idx]\n",
    "\n",
    "        min_length = min(len(peak_idx), len(valley_idx))\n",
    "\n",
    "        diff_peak_valley = [np.abs(peak_point[i] - valley_point[i]) for i in range(min_length)]\n",
    "        diff_peak_valley = np.array(diff_peak_valley)\n",
    "        \n",
    "        exceed = len(diff_peak_valley[diff_peak_valley>=threshold[cl]])\n",
    "        exceed_thres[cl].append(exceed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_sec = 20   # 3 sec/0.16 sec = 18.75 time point\n",
    "one_sec = 6      # 1 sec/0.16 sec = 6.25 time point\n",
    "\n",
    "cols = ['x_pca', 'y_pca', 'z_pca']\n",
    "threshold = [0.15, 0.13, 0.11]\n",
    "\n",
    "exceed_thres_nw = [[],[],[]]\n",
    "\n",
    "for cl in range(len(cols)):\n",
    "    c = cols[cl]\n",
    "    \n",
    "    for i in range(0, len(df_nonwalk)-three_sec, one_sec):\n",
    "        df_nonwalk_i = [df_nonwalk.loc[j, c] for j in range(i,i+three_sec)]\n",
    "        \n",
    "        peak_idx = detect_peaks(df_nonwalk_i)    \n",
    "        valley_idx = detect_peaks(df_nonwalk_i, valley=True)\n",
    "\n",
    "        peak_point = [df_nonwalk_i[j] for j in peak_idx]    \n",
    "        valley_point = [df_nonwalk_i[j] for j in valley_idx]\n",
    "\n",
    "        min_length = min(len(peak_idx), len(valley_idx))\n",
    "\n",
    "        diff_peak_valley = [np.abs(peak_point[i] - valley_point[i]) for i in range(min_length)]\n",
    "        diff_peak_valley = np.array(diff_peak_valley)\n",
    "        \n",
    "        exceed = len(diff_peak_valley[diff_peak_valley>=threshold[cl]])\n",
    "        exceed_thres_nw[cl].append(exceed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    f, axis = plt.subplots(figsize=(10,6))\n",
    "    ax = sns.distplot(exceed_thres[i], kde=False, ax=axis, label=cols[i])\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    f, axis = plt.subplots(figsize=(10,6))\n",
    "    ax = sns.distplot(exceed_thres_nw[i], kde=False, ax=axis, label=cols[i])\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dict_1 = {\n",
    "    'id': subj_all,\n",
    "    'x': [X_i[0] for X_i in X_all],\n",
    "    'y': [X_i[1] for X_i in X_all],\n",
    "    'z': [X_i[2] for X_i in X_all],\n",
    "    'x_pca': [X_i_pca[0] for X_i_pca in X_pca],\n",
    "    'y_pca': [X_i_pca[1] for X_i_pca in X_pca],\n",
    "    'z_pca': [X_i_pca[2] for X_i_pca in X_pca],\n",
    "    'roll': [rpy_pca_i[0] for rpy_pca_i in rpy_pca],\n",
    "    'pitch': [rpy_pca_i[1] for rpy_pca_i in rpy_pca],\n",
    "    'yaw': [rpy_pca_i[2] for rpy_pca_i in rpy_pca],\n",
    "    'label': y_all\n",
    "}\n",
    "\n",
    "df_rpy_1 = pd.DataFrame(X_dict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rpy_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_walk_1 = df_rpy_1[df_rpy_1['label']==label_dict['walk']]\n",
    "df_walk_1 = df_walk_1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonwalk_1 = df_rpy_1[df_rpy_1['label']!=label_dict['walk']]\n",
    "df_nonwalk_1 = df_nonwalk_1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['x_pca', 'y_pca', 'z_pca']\n",
    "all_avg_diff_1 = [[],[],[]]\n",
    "\n",
    "for subj_i in all_subjects:\n",
    "    df_walk_i = df_walk_1[df_walk_1['id']==subj_i]\n",
    "    df_walk_i = df_walk_i.reset_index(drop=True)\n",
    "    \n",
    "    print(subj_i)\n",
    "    \n",
    "    for i in range(len(cols)):\n",
    "        c = cols[i]\n",
    "        \n",
    "        peak_idx = detect_peaks(df_walk_i[c], show=True)    \n",
    "        valley_idx = detect_peaks(df_walk_i[c], valley=True, show=True)\n",
    "\n",
    "        peak_point = [df_walk_i.loc[i, c] for i in peak_idx]    \n",
    "        valley_point = [df_walk_i.loc[i, c] for i in valley_idx]\n",
    "\n",
    "        min_length = min(len(peak_idx), len(valley_idx))\n",
    "\n",
    "        diff_peak_valley = [np.abs(peak_point[i] - valley_point[i]) for i in range(min_length)]\n",
    "        avg_diff_pv = np.mean(diff_peak_valley)\n",
    "\n",
    "#         print(diff_peak_valley)\n",
    "        print(c, avg_diff_pv)\n",
    "        \n",
    "        all_avg_diff_1[i].append(avg_diff_pv)\n",
    "        \n",
    "all_avg_diff_1 = np.array(all_avg_diff_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['x_pca', 'y_pca', 'z_pca']\n",
    "all_avg_diff_nw_1 = [[],[],[]]\n",
    "\n",
    "for subj_i in all_subjects:\n",
    "    df_nonwalk_i = df_nonwalk_1[df_nonwalk_1['id']==subj_i]\n",
    "    df_nonwalk_i = df_nonwalk_i.reset_index(drop=True)\n",
    "    \n",
    "    print(subj_i)\n",
    "    \n",
    "    for i in range(len(cols)):\n",
    "        c = cols[i]\n",
    "        \n",
    "        peak_idx = detect_peaks(df_nonwalk_i[c], show=True)    \n",
    "        valley_idx = detect_peaks(df_nonwalk_i[c], valley=True, show=True)\n",
    "\n",
    "        peak_point = [df_nonwalk_i.loc[i, c] for i in peak_idx]    \n",
    "        valley_point = [df_nonwalk_i.loc[i, c] for i in valley_idx]\n",
    "\n",
    "        min_length = min(len(peak_idx), len(valley_idx)) - 1\n",
    "\n",
    "        diff_peak_valley = [np.abs(peak_point[i] - valley_point[i]) for i in range(min_length)]\n",
    "        avg_diff_pv = np.mean(diff_peak_valley)\n",
    "\n",
    "    #     print(diff_peak_valley)\n",
    "        print(c, avg_diff_pv)\n",
    "        \n",
    "        all_avg_diff_nw_1[i].append(avg_diff_pv)\n",
    "        \n",
    "all_avg_diff_nw_1 = np.array(all_avg_diff_nw_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aad_t_1 = all_avg_diff_1.transpose()\n",
    "\n",
    "print('walking for normal people')\n",
    "for i in range(len(aad_t_1)):\n",
    "    print(all_subjects[i], aad_t_1[i])\n",
    "    \n",
    "aad_t_nw_1 = all_avg_diff_nw_1.transpose()\n",
    "\n",
    "print()\n",
    "print('non-walking for normal people')\n",
    "for i in range(len(aad_t_nw_1)):\n",
    "    print(all_subjects[i], aad_t_nw_1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_sec = 20   # 3 sec/0.16 sec = 18.75 time point\n",
    "one_sec = 6      # 1 sec/0.16 sec = 6.25 time point\n",
    "\n",
    "cols = ['x_pca', 'y_pca', 'z_pca']\n",
    "threshold_1 = [0.28, 0.18, 0.18]\n",
    "\n",
    "exceed_thres_1 = [[],[],[]]\n",
    "\n",
    "for cl in range(len(cols)):\n",
    "    c = cols[cl]\n",
    "    \n",
    "    for i in range(0, len(df_walk_1)-three_sec, one_sec):\n",
    "        df_walk_i = [df_walk_1.loc[j, c] for j in range(i,i+three_sec)]\n",
    "        \n",
    "        peak_idx = detect_peaks(df_walk_i)    \n",
    "        valley_idx = detect_peaks(df_walk_i, valley=True)\n",
    "\n",
    "        peak_point = [df_walk_i[j] for j in peak_idx]    \n",
    "        valley_point = [df_walk_i[j] for j in valley_idx]\n",
    "\n",
    "        min_length = min(len(peak_idx), len(valley_idx))\n",
    "\n",
    "        diff_peak_valley = [np.abs(peak_point[i] - valley_point[i]) for i in range(min_length)]\n",
    "        diff_peak_valley = np.array(diff_peak_valley)\n",
    "        \n",
    "        exceed = len(diff_peak_valley[diff_peak_valley>=threshold_1[cl]])\n",
    "        exceed_thres_1[cl].append(exceed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_sec = 20   # 3 sec/0.16 sec = 18.75 time point\n",
    "one_sec = 6      # 1 sec/0.16 sec = 6.25 time point\n",
    "\n",
    "cols = ['x_pca', 'y_pca', 'z_pca']\n",
    "threshold_1 = [0.28, 0.18, 0.18]\n",
    "\n",
    "exceed_thres_nw_1 = [[],[],[]]\n",
    "\n",
    "for cl in range(len(cols)):\n",
    "    c = cols[cl]\n",
    "    \n",
    "    for i in range(0, len(df_nonwalk_1)-three_sec, one_sec):\n",
    "        df_nonwalk_i = [df_nonwalk_1.loc[j, c] for j in range(i,i+three_sec)]\n",
    "        \n",
    "        peak_idx = detect_peaks(df_nonwalk_i)    \n",
    "        valley_idx = detect_peaks(df_nonwalk_i, valley=True)\n",
    "\n",
    "        peak_point = [df_nonwalk_i[j] for j in peak_idx]    \n",
    "        valley_point = [df_nonwalk_i[j] for j in valley_idx]\n",
    "\n",
    "        min_length = min(len(peak_idx), len(valley_idx))\n",
    "\n",
    "        diff_peak_valley = [np.abs(peak_point[i] - valley_point[i]) for i in range(min_length)]\n",
    "        diff_peak_valley = np.array(diff_peak_valley)\n",
    "        \n",
    "        exceed = len(diff_peak_valley[diff_peak_valley>=threshold_1[cl]])\n",
    "        exceed_thres_nw_1[cl].append(exceed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    f, axis = plt.subplots(figsize=(10,6))\n",
    "    ax = sns.distplot(exceed_thres_1[i], kde=False, ax=axis, label=cols[i])\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    f, axis = plt.subplots(figsize=(10,6))\n",
    "    ax = sns.distplot(exceed_thres_nw_1[i], kde=False, ax=axis, label=cols[i])\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0,500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = nn_classifier(X_train, y_train)\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = basepath + 'model/knn_model.pkl'\n",
    "pickle.dump(nn_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_2 = nn_classifier(X_tr, y_tr)\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = nn_model_2.predict(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run eval_score.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['sit','sleep','stand','walk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(acc)\n",
    "\n",
    "show_conf_matrix(y_test, y_pred, LABELS)\n",
    "show_clf_report(y_test, y_pred, LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_te, y_pred_2)\n",
    "print(acc)\n",
    "\n",
    "show_conf_matrix(y_te, y_pred_2, LABELS)\n",
    "show_clf_report(y_te, y_pred_2, LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walk Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run classifier_alg.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['x_pca', 'y_pca', 'z_pca']\n",
    "xyz_pca = df_rpy[cols].to_dict(orient='split')['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify walking\n",
    "walk = calc_walk(X_all)\n",
    "walk_its = intersection_walk(walk)\n",
    "walk_pred_p = calc_walk_periods(walk_its)\n",
    "\n",
    "# walk_stairs_exact_p = get_exact_walk_stairs(y_all)\n",
    "walk_exact_p = get_exact_walk(y_all)\n",
    "    \n",
    "walk_pred = binarize_walk_prd(walk_pred_p, y_all)\n",
    "# walk_stairs_exact = binarize_walk_prd(walk_stairs_exact_p, y_all)\n",
    "walk_exact = binarize_walk_prd(walk_exact_p, y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk Algorithm Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_lbl = ['NaN','walk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(walk_exact, walk_pred)\n",
    "print(acc)\n",
    "\n",
    "show_conf_matrix(walk_exact, walk_pred, walk_lbl)\n",
    "show_clf_report(walk_exact, walk_pred, walk_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine SVM and Walk Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_new = combine(X_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred_new)\n",
    "print(acc)\n",
    "\n",
    "show_conf_matrix(y_test, y_pred_new, LABELS)\n",
    "show_clf_report(y_test, y_pred_new, LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model with Some Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run test_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = basepath + 'model/knn_model.pkl'\n",
    "\n",
    "model = pickle.load(open(filename,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects = [str(i) for i in range(1001,1009)]\n",
    "all_subjects.append('2001')\n",
    "all_subjects.append('2002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "call_functions(all_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_subjects = [str(i) for i in range(3001,3006)]\n",
    "\n",
    "call_functions(all_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s = '3004'\n",
    "df_sid = load_actual_timer(s)\n",
    "df_test = load_data(s, df_sid)\n",
    "\n",
    "X_vis_imp, ts_list_imp = preprocess_data(df_test, pca)\n",
    "df_y = predict(X_vis_imp, ts_list_imp)\n",
    "\n",
    "df_test, df_y = prepare_actual_lb(df_test, df_y, df_sid)\n",
    "\n",
    "actual_periods = get_actual_periods(df_test)\n",
    "pred_periods = get_predicted_periods(df_y)\n",
    "pp_all_run = postprocess_predicted(pred_periods, df_y)\n",
    "\n",
    "df_y['y_pred'] = pd.Series(pp_all_run)\n",
    "pp_periods = get_predicted_periods(df_y)\n",
    "plot_highlighted(s, df_test, pred_periods, pp_periods, actual_periods)\n",
    "\n",
    "evaluate(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['sit', 'sleep', 'stand', 'walk']\n",
    "\n",
    "df_y_notnull = df_y.dropna()\n",
    "df_y_notnull = df_y_notnull.reset_index(drop=True)\n",
    "\n",
    "actual_y = list(df_y_notnull['y_actual'])\n",
    "pred_y = list(df_y_notnull['y_pred'])\n",
    "\n",
    "last = len(pred_y)\n",
    "\n",
    "for i in range(len(pred_y)):\n",
    "    if(pred_y[i]==-1):\n",
    "        last = i\n",
    "        break\n",
    "\n",
    "pred_y = pred_y[:last]\n",
    "actual_y = actual_y[:last]\n",
    "\n",
    "acc = accuracy_score(actual_y, pred_y)\n",
    "print(acc)\n",
    "\n",
    "show_conf_matrix(actual_y, pred_y, LABELS)\n",
    "# show_clf_report(actual_y, pred_y, LABELS)\n",
    "\n",
    "labels_list = [0,1,2,3]\n",
    "report = classification_report(actual_y, pred_y, labels_list, output_dict=True)\n",
    "print(report['macro avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['x'][2200:].plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(s)\n",
    "print(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_period = []\n",
    "period_list = [[] for i in range(len(LABELS))]\n",
    "\n",
    "first = 0\n",
    "keep = 0\n",
    "\n",
    "for i in range(len(df_y)):\n",
    "    if(calc_sec(df_y.loc[i]['timestamp'].split(' ')[1])>=calc_sec(df_sid.loc[0]['timestamp'].split(' ')[1]) and\n",
    "       calc_sec(df_y.loc[i]['timestamp'].split(' ')[1])<=calc_sec(df_sid.loc[len(df_sid)-1]['timestamp'].split(' ')[1])):\n",
    "        \n",
    "        keep_lb = df_y.loc[keep]['y_pred']\n",
    "\n",
    "        if(keep_lb!=df_y.loc[i]['y_pred']):\n",
    "            label_period.append([df_y.loc[keep]['timestamp'], df_y.loc[i-1]['timestamp'], \n",
    "                                 df_y.loc[i-1]['y_pred']])\n",
    "\n",
    "            period_list[df_y.loc[i-1]['y_pred']].append([df_y.loc[keep]['timestamp'], df_y.loc[i-1]['timestamp']])\n",
    "\n",
    "            keep = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = ['sit', 'sleep', 'stand', 'walk']\n",
    "headers = ['start', 'end', 'pred']\n",
    "\n",
    "t = PrettyTable(headers)\n",
    "\n",
    "for row in label_period:\n",
    "#     if(calc_sec(row[1].split(' ')[1])-calc_sec(row[0].split(' ')[1])>1):\n",
    "    t.add_row([row[0], row[1], labels_list[row[2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(label_period))\n",
    "\n",
    "label_cnt_list = [0 for i in range(len(labels_list))]\n",
    "for lb_p in label_period:\n",
    "    label_i = lb_p[2]\n",
    "    \n",
    "    label_cnt_list[label_i] += 1\n",
    "\n",
    "activity_changes = []\n",
    "for i in range(len(labels_list)):\n",
    "    activity_changes.append([labels_list[i], label_cnt_list[i]])\n",
    "    \n",
    "print(activity_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Label', 'Activities Count']\n",
    "tabl_act_chng = PrettyTable(headers)\n",
    "\n",
    "for ac in activity_changes:\n",
    "    tabl_act_chng.add_row([ac[0], ac[1]])\n",
    "    \n",
    "tabl_act_chng.add_row(['', ''])\n",
    "tabl_act_chng.add_row(['total changes', len(label_period)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(tabl_act_chng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Inactive AC (ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Label', 'Activities Count']\n",
    "tabl_act = PrettyTable(headers)\n",
    "inactive_table = []\n",
    "active_table = []\n",
    "\n",
    "sum = 0\n",
    "sum_2 = 0\n",
    "for ac in activity_changes:\n",
    "    if(ac[0] == 'sit' or ac[0] == 'sleep'):\n",
    "        sum += ac[1]\n",
    "    else :\n",
    "        sum_2 += ac[1]\n",
    "\n",
    "tabl_act.add_row(['Inactive', sum])\n",
    "tabl_act.add_row(['Active', sum_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabl_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Time to String Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time_to_string(sec):\n",
    "    minute = math.floor(sec/60)\n",
    "    sec = int(sec%60)\n",
    "\n",
    "    time_string = str(minute) + ':' + str(sec)\n",
    "    if(sec<10):\n",
    "        time_string = str(minute) + ':0' + str(sec)\n",
    "    \n",
    "    return time_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicted Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_secs = []\n",
    "for i in range(len(period_list)):    \n",
    "    secs = 0\n",
    "    for p_i in period_list[i]:\n",
    "        sec = calc_sec(p_i[1].split(' ')[1]) - calc_sec(p_i[0].split(' ')[1])\n",
    "        secs += sec\n",
    "    \n",
    "    secs = round(secs, 3)\n",
    "    total_secs.append(secs)\n",
    "    \n",
    "percent_secs = [round(t/np.sum(total_secs)*100, 3) for t in total_secs]\n",
    "\n",
    "tb = PrettyTable(['Label', 'Minutes', 'Percentage', 'Activity Count'])\n",
    "\n",
    "for i in range(len(LABELS)):\n",
    "    tb.add_row([labels_list[i], convert_time_to_string(total_secs[i]), percent_secs[i], label_cnt_list[i]])\n",
    "\n",
    "tb.add_row(['', '', '',''])\n",
    "tb.add_row(['total', convert_time_to_string(round(np.sum(total_secs), 3)), \n",
    "            round(np.sum(percent_secs), 3), len(label_period)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lb = df_sid.groupby('label')\n",
    "\n",
    "dura_dict = {}\n",
    "for lb in labels_list:\n",
    "    dura_dict[lb] = 0\n",
    "\n",
    "idx = list(df_sid.index)\n",
    "for i in range(len(labels_list)):\n",
    "    lb = labels_list[i]\n",
    "    df_temp = df_lb.get_group(lb)\n",
    "    df_temp = df_temp.reset_index(drop=True)\n",
    "        \n",
    "    if(lb=='downstairs' or lb=='upstairs'):\n",
    "        lb = 'walk'\n",
    "    \n",
    "    for j in range(len(df_temp)):\n",
    "        dura_dict[lb] += calc_sec(df_temp.loc[j]['duration'])\n",
    "        \n",
    "total_dura = np.sum([dura_dict[lb] for lb in labels_list])\n",
    "\n",
    "percent_list = []\n",
    "        \n",
    "tabl = PrettyTable(['Label', 'Minutes', 'Percentage'])\n",
    "for lb in labels_list:\n",
    "    percent = round(dura_dict[lb]/total_dura*100, 3)\n",
    "    tabl.add_row([lb, convert_time_to_string(dura_dict[lb]), round(dura_dict[lb]/total_dura*100, 3)])\n",
    "    \n",
    "    percent_list.append(percent)\n",
    "    \n",
    "tabl.add_row(['', '', ''])    \n",
    "tabl.add_row(['total', convert_time_to_string(total_dura), round(np.sum(percent_list), 3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Durations Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Prediction')\n",
    "print(tb)\n",
    "\n",
    "print('Actual')\n",
    "print(tabl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar Chart for Every 5 Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_idx = 0\n",
    "f_idx = 1\n",
    "lb_idx = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Each 5 Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fivemin = 60*5\n",
    "new_label_period = []\n",
    "\n",
    "start_time = calc_sec(label_period[0][s_idx].split(' ')[1])\n",
    "finish_time = calc_sec(label_period[-1][f_idx].split(' ')[1])\n",
    "\n",
    "floor_start = start_time - (start_time%fivemin)\n",
    "ceil_finish = finish_time - (finish_time%fivemin) + fivemin\n",
    "\n",
    "print(calc_ts(floor_start), calc_ts(ceil_finish))\n",
    "\n",
    "tm_s = floor_start\n",
    "tm_f = floor_start + fivemin\n",
    "date = label_period[0][s_idx].split(' ')[0]\n",
    "\n",
    "for prd in label_period:\n",
    "    if(calc_sec(prd[f_idx].split(' ')[1])>=tm_f):\n",
    "        new_prd = [prd[s_idx], date + ' ' + calc_ts(tm_f), prd[lb_idx]]\n",
    "        new_label_period.append(new_prd)\n",
    "        \n",
    "        tm_s += fivemin\n",
    "        tm_f += fivemin\n",
    "    else:\n",
    "        new_label_period.append(prd)\n",
    "                \n",
    "    if(calc_sec(prd[s_idx].split(' ')[1])<tm_s):\n",
    "        new_prd = [date + ' ' + calc_ts(tm_s), prd[f_idx], prd[lb_idx]]\n",
    "        new_label_period.append(new_prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_periods_label = []\n",
    "\n",
    "for t_i in range(int(floor_start), int(ceil_finish), fivemin):\n",
    "    period_lb = [0 for i in range(len(LABELS))]\n",
    "    for prd in new_label_period:\n",
    "        if(calc_sec(prd[s_idx].split(' ')[1])>=t_i and calc_sec(prd[f_idx].split(' ')[1])<=t_i+fivemin):\n",
    "            period_lb[prd[lb_idx]] += calc_sec(prd[f_idx].split(' ')[1])-calc_sec(prd[s_idx].split(' ')[1])\n",
    "            period_lb[prd[lb_idx]] = round(period_lb[prd[lb_idx]], 3)\n",
    "            \n",
    "    all_periods_label.append(period_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame(all_periods_label, columns=labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Bar Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = list(range(len(df_all['sit'])))\n",
    "width = 0.2\n",
    "colors = ['crimson','gold','lime','dodgerblue']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "for i in range(len(LABELS)):\n",
    "    plt.bar([p + i*width for p in pos],\n",
    "            df_all[labels_list[i]],\n",
    "            width,\n",
    "            alpha=0.5,\n",
    "            color=colors[i],\n",
    "            label=labels_list[i])\n",
    "    \n",
    "ax.set_xticks([p + 1.5 * width for p in pos])\n",
    "\n",
    "xtick_labels = [calc_ts(floor_start + i*fivemin) + '-' + calc_ts(floor_start + (i+1)*fivemin)\n",
    "                for i in range(len(df_all))]\n",
    "ax.set_xticklabels(xtick_labels)\n",
    "\n",
    "ax.set_ylabel('Time (sec)')\n",
    "\n",
    "plt.xlim(min(pos)-width, max(pos)+width*4)\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Activity Summary for Subject ID: ' + s)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DDC_run.ipynb",
   "provenance": [
    {
     "file_id": "1uW9RzCQha3RZ_wzM_gLxhAN7ytclHWHC",
     "timestamp": 1548220076491
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
