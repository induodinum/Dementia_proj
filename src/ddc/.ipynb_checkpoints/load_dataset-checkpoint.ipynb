{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "\n",
    "from os import listdir, walk\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Timestamp Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sec(time):\n",
    "    hms = time.split(':')\n",
    "    hms = [float(x) for x in hms]\n",
    "    sec = hms[2] + hms[1]*60 + hms[0]*3600\n",
    "    sec = round(sec,3)\n",
    "    return sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ts(sec):\n",
    "    ts = ''\n",
    "    hr = int(sec/3600)\n",
    "    mn = int((sec - (hr*3600))/60)\n",
    "    sc = sec - (hr*3600) - (mn*60)\n",
    "    sc = round(sc,3)\n",
    "    ts += str(hr) + ':' + str(mn) + ':' + str(sc)\n",
    "    # print(ts)\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_t_period(dates,secs):\n",
    "    t_period = []\n",
    "    \n",
    "    start_sec = secs[0]\n",
    "    prev_sec = secs[0]\n",
    "    prev_date = dates[0]\n",
    "\n",
    "    for i in range(len(secs)):\n",
    "        curr_sec = secs[i]\n",
    "        diff_sec = curr_sec - prev_sec\n",
    "        curr_date = dates[i]\n",
    "        \n",
    "        if((diff_sec>3.0) and (curr_date==prev_date)):\n",
    "            t_period.append([curr_date,start_sec,prev_sec])\n",
    "            start_sec = curr_sec\n",
    "        elif(curr_date!=prev_date):\n",
    "            t_period.append([prev_date,start_sec,prev_sec])\n",
    "            start_sec = curr_sec\n",
    "            prev_date = curr_date\n",
    "        elif(i==len(secs)-1):\n",
    "            t_period.append([curr_date,start_sec,curr_sec])\n",
    "\n",
    "        prev_sec = curr_sec\n",
    "    \n",
    "    return t_period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve file directories from Google Drive\n",
    "mypath = '../../DDC_Data/'\n",
    "basepath = '../../'\n",
    "\n",
    "dir_ = [f for f in walk(mypath)]\n",
    "# print(dir_)\n",
    "\n",
    "dir = list(dir_[0])\n",
    "dir[1] = sorted(dir[1])\n",
    "\n",
    "outer_path = dir[0]\n",
    "sub_path = dir[1]\n",
    "\n",
    "folders = [join(outer_path,d) for d in sub_path]\n",
    "\n",
    "files = []\n",
    "for fd in folders:\n",
    "    temp_f = [f for f in listdir(fd) if isfile(join(fd, f)) and f[-3:]=='csv' and f[5:9]!='data' and f[:4]==fd[-4:]]\n",
    "    temp_f = sorted(temp_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve All Timestamp Periods from a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects = []\n",
    "\n",
    "for i in range(1001,1013):\n",
    "    all_subjects.append(str(i))\n",
    "\n",
    "for i in range(2001,2003):\n",
    "    all_subjects.append(str(i))\n",
    "\n",
    "# print(all_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_thai_language():\n",
    "    # -- coding: utf-8 --\n",
    "\n",
    "    filepath = '/Users/admin/Downloads/history_amdtimer.csv'\n",
    "\n",
    "    df = pd.read_csv(filepath, header=None, names=['sid','raw_label', 'timestamp', 'duration','label'])\n",
    "\n",
    "    temp_series = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        if(df.iloc[i][1]=='ยืน'):\n",
    "            temp_series.append('stand')\n",
    "\n",
    "        elif(df.iloc[i][1]=='นั่ง'):\n",
    "            temp_series.append('sit')\n",
    "\n",
    "        elif(df.iloc[i][1]=='นอน'):\n",
    "            temp_series.append('sleep')\n",
    "\n",
    "        elif(df.iloc[i][1]=='เดิน'):\n",
    "            temp_series.append('walk')\n",
    "\n",
    "        elif(df.iloc[i][1]=='ขึ้นบันได'):\n",
    "            temp_series.append('walk')\n",
    "\n",
    "        elif(df.iloc[i][1]=='ลงบันได'):\n",
    "            temp_series.append('walk')\n",
    "\n",
    "        else:\n",
    "            temp_series.append(df.loc[i]['raw_label'])\n",
    "\n",
    "    df['label'] = pd.Series(temp_series)\n",
    "    df['raw_label'] = df['label']\n",
    "    df = df.drop(columns=['label'])\n",
    "\n",
    "#     print(df)\n",
    "    df.to_csv('iphone-history_amdtimer.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_subj_id(i):\n",
    "    subject_id = all_subjects[i]\n",
    "\n",
    "    directory = basepath + 'Graphs/' + subject_id\n",
    "\n",
    "    if(not os.path.exists(directory)):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    return subject_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_timer(subject_id):\n",
    "  # Configure starting and ending time values\n",
    "    sid_dir = mypath + '/' + subject_id\n",
    "    sid_files = [f for f in listdir(sid_dir) if 'history_amdtimer' in f]\n",
    "\n",
    "    sid_filepath = sid_dir + '/' + sid_files[0]\n",
    "\n",
    "    # Timestamp periods dataframe\n",
    "    timer_df = pd.read_csv(sid_filepath, header=None, names=['sid','raw_label', 'timestamp', 'duration','label'])\n",
    "\n",
    "    filtered_timer = [i for i in timer_df['sid'] if i==int(subject_id)]\n",
    "\n",
    "    timer_filt = timer_df[timer_df['sid'].isin(filtered_timer)]\n",
    "    timer_filt = timer_filt.reset_index(drop=True)\n",
    "    \n",
    "    timer_arr = []\n",
    "    \n",
    "    for i in range(len(timer_filt)):\n",
    "        if(timer_filt.loc[i]['raw_label']=='upstairs' or \n",
    "          timer_filt.loc[i]['raw_label']=='downstairs'):\n",
    "            timer_arr.append('walk')\n",
    "        else:\n",
    "            timer_arr.append(timer_filt.loc[i]['raw_label'])\n",
    "\n",
    "    timer_filt['label'] = pd.Series(timer_arr)\n",
    "    \n",
    "    start_ts = timer_filt.loc[0]['timestamp']\n",
    "    end_ts = timer_filt.loc[len(timer_filt)-1]['timestamp']\n",
    "\n",
    "    rec_date = start_ts[:10]\n",
    "    start_time = start_ts[11:]\n",
    "    end_time = end_ts[11:]\n",
    "\n",
    "#     print(timer_filt)\n",
    "    \n",
    "    return timer_filt, rec_date, start_time, end_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe of ACC and HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_acc(subject_id):\n",
    "    # Load accelerations\n",
    "    acc_filepath = mypath + '/' + subject_id + '/' + subject_id + '-log_acc.csv'\n",
    "\n",
    "    df = pd.read_csv(acc_filepath, header=None, names=['x','y','z','timestamp'])\n",
    "\n",
    "    filtered = [i for i in df['timestamp'] if str(i)[:10]==rec_date and calc_sec(str(i)[11:])>=calc_sec(start_time) \n",
    "              and calc_sec(str(i)[11:])<=calc_sec(end_time)]\n",
    "\n",
    "    df_filt = df[df['timestamp'].isin(filtered)]\n",
    "    df_filt = df_filt.reset_index(drop=True)\n",
    "\n",
    "    cols = ['timestamp','x','y','z']\n",
    "    df_filt = df_filt[cols]\n",
    "\n",
    "    return df_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hr(subject_id):\n",
    "    # Load heart rate\n",
    "    hr_filepath = mypath + '/' + subject_id + '/' + subject_id + '-log_hr.csv'\n",
    "\n",
    "    df2 = pd.read_csv(hr_filepath, header=None, names=['hr','timestamp'])\n",
    "\n",
    "    filtered = [i for i in df2['timestamp'] if i[:10]==rec_date and calc_sec(i[11:])>=calc_sec(start_time) \n",
    "              and calc_sec(i[11:])<=calc_sec(end_time)]\n",
    "\n",
    "    df_hr = df2[df2['timestamp'].isin(filtered)]\n",
    "    df_hr = df_hr.reset_index(drop=True)\n",
    "\n",
    "    cols = ['timestamp','hr']\n",
    "    df_hr = df_hr[cols]\n",
    "\n",
    "    return df_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_acc_and_hr(df_filt, df_hr):\n",
    "    # Fill in missing HRs\n",
    "    hr_cnt = 0\n",
    "\n",
    "    for i in range(len(df_filt)):\n",
    "        hr_time = df_hr.loc[hr_cnt,'timestamp'].split(' ')[1]\n",
    "        filt_time = df_filt.loc[i,'timestamp'].split(' ')[1]\n",
    "\n",
    "        if(calc_sec(hr_time)<=calc_sec(filt_time)):\n",
    "            if(hr_cnt<len(df_hr)-1):\n",
    "                hr_cnt += 1\n",
    "        df_filt.loc[i,'HR'] = df_hr.loc[hr_cnt,'hr']\n",
    "\n",
    "    # Normalize by dividing by g (standard gravity)\n",
    "    g = 9.8\n",
    "    df_filt.loc[:,'x'] = df_filt['x'].apply(lambda x: x/g)\n",
    "    df_filt.loc[:,'y'] = df_filt['y'].apply(lambda x: x/g)\n",
    "    df_filt.loc[:,'z'] = df_filt['z'].apply(lambda x: x/g)\n",
    "\n",
    "    return df_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Activity Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_i_bar = [0.00349329,0.00465817,0.00543154]\n",
    "std_i_bar = np.array(std_i_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equation_bai(X_i):\n",
    "    all_std = []\n",
    "    \n",
    "    std_i = np.std(X_i,axis=0)\n",
    "    diff_std = std_i**2 - std_i_bar**2\n",
    "    diff_std = (diff_std + 1) / (std_i_bar**2 + 1)\n",
    "    \n",
    "    diff_std_ = std_i**2\n",
    "\n",
    "    all_std.append(diff_std)\n",
    "    \n",
    "    all_std = np.array(all_std)\n",
    "    \n",
    "    ai = np.sum(all_std**2,axis=1)/3\n",
    "    ai[ai<0] = 0\n",
    "    ai = np.sqrt(ai)\n",
    "    \n",
    "    return ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ai(df1):\n",
    "    H = 10\n",
    "    ai1 = []\n",
    "\n",
    "    for i in range(len(df1)):\n",
    "        xyz_val = []\n",
    "        if(i-H>=0):\n",
    "            for j in range(H,0,-1):\n",
    "                xyz_val.append([df1.iloc[i-j,1],df1.iloc[i-j,2],df1.iloc[i-j,3]])\n",
    "            ai_val = float(equation_bai(xyz_val))\n",
    "            ai1.append(ai_val)\n",
    "        else:\n",
    "            ai1.append(1)\n",
    "\n",
    "    return ai1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colors for Each Acitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_time_periods(timer_filt):\n",
    "    t_ = [calc_sec(t.split(' ')[1]) for t in timer_filt['timestamp']]\n",
    "    duration = [d for d in timer_filt['duration']]\n",
    "    lb_ = [lb for lb in timer_filt['label']]\n",
    "\n",
    "    t_end = [t_[i]+calc_sec(duration[i]) for i in range(len(t_))]  \n",
    "\n",
    "    ts_ = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(t_)):\n",
    "        ts_.append(calc_sec(duration[i]))\n",
    "        labels.append(lb_[i])\n",
    "        if(i+1<len(t_)-1):\n",
    "            ts_.append(round(t_[i+1]-t_end[i],3))\n",
    "            labels.append('NaN')\n",
    "\n",
    "    return ts_, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_color_labels(ts_, labels):\n",
    "  \n",
    "    accum = 0\n",
    "    ts = []\n",
    "    for x in ts_:\n",
    "        accum += x\n",
    "        ts.append(round(accum,3))\n",
    "\n",
    "    lb_set = set()\n",
    "    for x in labels:\n",
    "        lb_set.add(x)\n",
    "\n",
    "    lb_ = list(lb_set)\n",
    "\n",
    "    set_cnt = []\n",
    "    for i in range(len(lb_)):\n",
    "        set_cnt.append(0)\n",
    "\n",
    "    lb = []\n",
    "    lb.append('NaN')\n",
    "\n",
    "    for x in labels:\n",
    "        for i in range(len(lb_)):\n",
    "            if(lb_[i]==x and set_cnt[i]!=1 and lb_[i]!='NaN'):\n",
    "                set_cnt[i] = 1\n",
    "                lb.append(x)\n",
    "\n",
    "    colors = ['#808080', '#E6194B', '#3CB44B', '#FFE119', '#4363D8', '#F58231',\n",
    "            '#911EB4', '#46F0F0', '#F032E6', '#BCF60C', '#008080', '#E6BEFF', \n",
    "            '#9A6324', '#800000', '#AAFFC3', '#808000', '#000075']\n",
    "\n",
    "    color_dict = {}\n",
    "    for i in range(len(lb)):\n",
    "        color_dict[lb[i]] = colors[i]\n",
    "\n",
    "    #   print(color_dict)\n",
    "\n",
    "    lb_color = []\n",
    "    for x in labels:\n",
    "        lb_color.append(color_dict[x])\n",
    "\n",
    "    return ts, lb_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ACC, AI with Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ai(df1, ts, lb_color):\n",
    "    dict1 = df1.to_dict(orient='list')\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(16,12))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    ts_cnt = 0\n",
    "    x_axis = []\n",
    "    y_ai = []\n",
    "\n",
    "    ax = axes[0]\n",
    "    ax.plot(dict1['x'],color='r',label='X')\n",
    "    ax.plot(dict1['y'],color='g',label='Y')\n",
    "    ax.plot(dict1['z'],color='b',label='Z')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_title('X,Y,Z')\n",
    "\n",
    "    ax = axes[1]\n",
    "    for i in range(len(dict1['timestamp'])):\n",
    "        if(dict1['AI'][i]>0):\n",
    "            if(calc_sec(dict1['timestamp'][i].split(' ')[1])>calc_sec(start_time)+ts[ts_cnt]):\n",
    "                ax.plot(x_axis,y_ai,color=lb_color[ts_cnt])\n",
    "                ts_cnt += 1\n",
    "                x_axis = []\n",
    "                y_ai = []\n",
    "\n",
    "            elif(ts_cnt==len(lb_color)-1):\n",
    "                ax.plot(x_axis,y_ai,color=lb_color[ts_cnt])\n",
    "\n",
    "            x_axis.append(i)\n",
    "            y_ai.append(dict1['AI'][i])\n",
    "\n",
    "    ax.set_title('Activity Index')\n",
    "\n",
    "    fig.savefig(basepath + 'Graphs/' + subject_id + '/' + subject_id + '_ddc_run.png', dpi = 300)\n",
    "\n",
    "    #   plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataframe with AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai(subject_id):\n",
    "    df_filt = load_acc(subject_id)\n",
    "    df_hr = load_hr(subject_id)\n",
    "\n",
    "    df1 = merge_acc_and_hr(df_filt, df_hr)\n",
    "    ai1 = calc_ai(df1)\n",
    "\n",
    "    df1['AI'] = pd.Series(ai1)\n",
    "\n",
    "    ts_, labels = prepare_time_periods(df_timer)\n",
    "    ts, lb_color = prepare_color_labels(ts_, labels)\n",
    "\n",
    "    #   print(ts_, lb_color)\n",
    "\n",
    "    return df1, ai1, ts, lb_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate Data by Labels of Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class period:\n",
    "    def __init__(self, s, f):\n",
    "        self.s = s\n",
    "        self.f = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_label(df1, df_timer, df_list, labels):\n",
    "  \n",
    "    df_label = df_timer.groupby('label')\n",
    "    td_col = ['timestamp','duration']\n",
    "\n",
    "    for x in df_label:\n",
    "    # x[0] is a label\n",
    "    # x[1] is a groupby object\n",
    "\n",
    "        df_label_x = df_label.get_group(x[0])\n",
    "        df_label_x = df_label_x.reset_index(drop=True)\n",
    "\n",
    "        temp_ts = [period(df_label_x.loc[a]['timestamp'].split(' ')[1], \n",
    "                    calc_ts( calc_sec(df_label_x.loc[a]['timestamp'].split(' ')[1])+\n",
    "                            calc_sec(df_label_x.loc[a]['duration']) )) \n",
    "                    for a in range(len(df_label_x))]\n",
    "\n",
    "        for a in temp_ts:\n",
    "            filter_ = [i for i in df1['timestamp'] \n",
    "                    if calc_sec(i.split(' ')[1])>=calc_sec(a.s) and calc_sec(i.split(' ')[1])<=calc_sec(a.f)]\n",
    "\n",
    "            df1_new = df1[df1['timestamp'].isin(filter_)]\n",
    "            df1_new = df1_new.reset_index(drop=True)\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                if(labels[i]==x[0]):\n",
    "                    df_list[i] = df_list[i].append(df1_new)\n",
    "\n",
    "    return df_list    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe List Grouped by Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_dataframe(df1, df_timer):\n",
    "    df_list = []\n",
    "    cols = ['timestamp','x','y','z','HR','AI']\n",
    "\n",
    "    lbl = set()\n",
    "    for tm in range(len(df_timer)):\n",
    "        lbl.add(df_timer.loc[tm]['label'])\n",
    "\n",
    "    LABELS = sorted(list(lbl))\n",
    "\n",
    "    # dictionary mapped from activity label to index\n",
    "    label_dict = {\n",
    "      'sit': 0,\n",
    "      'sleep': 1,\n",
    "      'stand': 2,\n",
    "      'walk': 3\n",
    "    }\n",
    "\n",
    "    for i in range(len(LABELS)):\n",
    "        df_null = pd.DataFrame(columns=cols)\n",
    "        df_null = df_null.fillna(0)\n",
    "\n",
    "        df_list.append(df_null)\n",
    "\n",
    "    df_list = separate_label(df1, df_timer, df_list, LABELS)\n",
    "\n",
    "    for i in range(len(df_list)):\n",
    "        df_list[i] = df_list[i].reset_index(drop=True)\n",
    "\n",
    "    return df_list, label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Plots of Grouped Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grouped_df(df_list, label_dict):\n",
    "    xyz = ['x','y','z']\n",
    "    xyz_color = ['r','g','b']\n",
    "\n",
    "    for x in label_dict:\n",
    "    #     print(label_dict[x])\n",
    "\n",
    "        figure = plt.figure(figsize=(20,6))\n",
    "        figure.tight_layout()\n",
    "\n",
    "        cnt = 1\n",
    "\n",
    "        for i in range(len(xyz)):\n",
    "            ax = plt.subplot(1, len(xyz), cnt)\n",
    "\n",
    "            ax.set_ylim(top=1.5, bottom=-3.0)\n",
    "            ax.plot(df_list[label_dict[x]][xyz[i]], label=xyz[i], color=xyz_color[i])\n",
    "            ax.legend(loc='upper right')\n",
    "            ax.set_title(xyz[i] + '-axis for activity ' + x + ' subject no. ' + subject_id)\n",
    "\n",
    "            cnt += 1\n",
    "\n",
    "        figure.savefig(basepath + 'Graphs/ddc_' + x + '/' + subject_id + '.png', dpi=300)\n",
    "\n",
    "    #     plt.show()\n",
    "\n",
    "    # close the figure\n",
    "    plt.close(figure) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get X and y from Dataset for Each Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(df_list, label_dict):\n",
    "    feature_cols = ['x','y','z']\n",
    "    count = 0\n",
    "\n",
    "    for x in label_dict:\n",
    "#         print(x)\n",
    "    \n",
    "        X_series = df_list[label_dict[x]][feature_cols]\n",
    "        y_series = [label_dict[x] for i in range(len(df_list[label_dict[x]]))]\n",
    "\n",
    "        X_train = X_series.values.reshape((len(X_series),3))\n",
    "        y_train = np.array(y_series)\n",
    "\n",
    "          # 'downstairs': 0,\n",
    "          # 'sit': 1,\n",
    "          # 'sleep': 2,\n",
    "          # 'stand': 3,\n",
    "          # 'upstairs': 4,\n",
    "          # 'walk': 5\n",
    "            \n",
    "        if(count==0):\n",
    "            X_train_axes = X_train\n",
    "            y_train_axes = y_train\n",
    "            count += 1\n",
    "\n",
    "        else:\n",
    "            X_train_axes = np.vstack((X_train_axes, X_train))\n",
    "            y_train_axes = np.hstack((y_train_axes, y_train))\n",
    "\n",
    "    X_train_axes = np.array(X_train_axes)\n",
    "    y_train_axes = np.array(y_train_axes)\n",
    "    #     print(length)\n",
    "\n",
    "    return X_train_axes, y_train_axes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Call *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1001's data\n",
      "                    timestamp         x         y         z          HR  \\\n",
      "0     2019-01-14 14:52:31.035 -0.956459 -0.203385  0.164418   86.937775   \n",
      "1     2019-01-14 14:52:31.193 -0.957925 -0.198499  0.156600   86.937775   \n",
      "2     2019-01-14 14:52:31.356 -0.956459 -0.197522  0.162952   86.937775   \n",
      "3     2019-01-14 14:52:31.514 -0.953527 -0.198010  0.162952   86.937775   \n",
      "4     2019-01-14 14:52:31.675 -0.953527 -0.200942  0.166861   87.511505   \n",
      "5     2019-01-14 14:52:31.836 -0.951573 -0.196056  0.164418   87.511505   \n",
      "6     2019-01-14 14:52:31.997 -0.956459 -0.195079  0.168816   87.511505   \n",
      "7     2019-01-14 14:52:32.158 -0.956459 -0.198499  0.164418   87.511505   \n",
      "8     2019-01-14 14:52:32.318 -0.970140 -0.202896  0.174679   87.511505   \n",
      "9     2019-01-14 14:52:32.479 -0.967209 -0.202896  0.152691   87.511505   \n",
      "10     2019-01-14 14:52:32.64 -0.959391 -0.194101  0.170770   87.511505   \n",
      "11      2019-01-14 14:52:32.8 -0.962811 -0.200942  0.166861   88.143845   \n",
      "12    2019-01-14 14:52:32.963 -0.950107 -0.191170  0.158066   88.143845   \n",
      "13    2019-01-14 14:52:33.124 -0.948641 -0.241008  0.164418   88.143845   \n",
      "14    2019-01-14 14:52:33.283 -0.952550 -0.229770  0.148783   88.143845   \n",
      "15    2019-01-14 14:52:33.445 -0.959391 -0.185306  0.153669   88.143845   \n",
      "16    2019-01-14 14:52:33.604 -0.955482 -0.188727  0.150248   88.143845   \n",
      "17    2019-01-14 14:52:33.767 -0.957925 -0.202408  0.150248   88.143845   \n",
      "18    2019-01-14 14:52:33.925 -0.959879 -0.200942  0.143408   88.460014   \n",
      "19    2019-01-14 14:52:34.086 -0.968186 -0.192636  0.146339   88.460014   \n",
      "20    2019-01-14 14:52:34.247 -0.943267 -0.201431  0.150737   88.460014   \n",
      "21    2019-01-14 14:52:34.408 -0.959879 -0.211691  0.135590   88.460014   \n",
      "22    2019-01-14 14:52:34.568 -0.978447 -0.206317  0.156112   88.460014   \n",
      "23    2019-01-14 14:52:34.729 -0.960368 -0.200942  0.122397   88.460014   \n",
      "24     2019-01-14 14:52:34.89 -0.956948 -0.221952  0.139988   88.460014   \n",
      "25     2019-01-14 14:52:35.05 -0.946687 -0.197033  0.134613   88.618100   \n",
      "26    2019-01-14 14:52:35.213 -0.975026 -0.180909  0.142919   88.618100   \n",
      "27    2019-01-14 14:52:35.372 -0.966231 -0.193124  0.132658   88.618100   \n",
      "28    2019-01-14 14:52:35.535 -0.962322 -0.194590  0.137544   88.618100   \n",
      "29    2019-01-14 14:52:35.695 -0.948641 -0.181397  0.131681   88.618100   \n",
      "...                       ...       ...       ...       ...         ...   \n",
      "3790  2019-01-14 15:02:40.143 -0.814273 -0.281807  0.160143  105.565506   \n",
      "3791  2019-01-14 15:02:40.303 -1.020956 -0.280341  0.228549  105.565506   \n",
      "3792  2019-01-14 15:02:40.462 -0.805478 -0.212913  0.081476  105.565506   \n",
      "3793  2019-01-14 15:02:40.623 -0.809875 -0.217310  0.093691  105.565506   \n",
      "3794  2019-01-14 15:02:40.786 -0.907598 -0.290602  0.147439  105.565506   \n",
      "3795  2019-01-14 15:02:40.945 -1.535832 -0.266660  0.071215  105.565506   \n",
      "3796  2019-01-14 15:02:41.105 -0.673064 -0.248582  0.052648  105.770600   \n",
      "3797  2019-01-14 15:02:41.266 -0.982356 -0.239298 -0.020522  105.770600   \n",
      "3798  2019-01-14 15:02:41.426 -0.857759 -0.247116 -0.006841  105.770600   \n",
      "3799  2019-01-14 15:02:41.587 -0.777138 -0.357054 -0.036157  105.770600   \n",
      "3800  2019-01-14 15:02:41.748 -1.506026 -0.425459 -0.038600  105.770600   \n",
      "3801   2019-01-14 15:02:41.91 -1.004832 -0.124474 -0.074758  105.770600   \n",
      "3802   2019-01-14 15:02:42.07 -0.824534 -0.397120 -0.052282  105.770600   \n",
      "3803   2019-01-14 15:02:42.23 -0.796683 -0.424482 -0.102120  105.873146   \n",
      "3804  2019-01-14 15:02:42.391 -0.958414 -0.327248 -0.127528  105.873146   \n",
      "3805  2019-01-14 15:02:42.551 -0.928608 -0.432300 -0.033714  105.873146   \n",
      "3806  2019-01-14 15:02:42.714 -0.934472 -0.931173 -0.078178  105.873146   \n",
      "3807  2019-01-14 15:02:42.874 -0.577296 -0.852995  0.262263  105.873146   \n",
      "3808  2019-01-14 15:02:43.034 -0.396509 -0.849087  0.226594  105.873146   \n",
      "3809  2019-01-14 15:02:43.196 -0.246994 -0.803646  0.257377  105.873146   \n",
      "3810  2019-01-14 15:02:43.358 -0.336410 -0.929708  0.037501  105.773630   \n",
      "3811  2019-01-14 15:02:43.518 -0.225983 -0.715695  0.077567  105.773630   \n",
      "3812  2019-01-14 15:02:43.677 -0.691143 -0.965865 -0.501805  105.773630   \n",
      "3813  2019-01-14 15:02:43.837  0.144751 -0.875960 -0.378675  105.773630   \n",
      "3814  2019-01-14 15:02:43.998 -0.061321 -0.515853  0.364383  105.773630   \n",
      "3815  2019-01-14 15:02:44.159  0.286938 -0.220242  1.434322  105.773630   \n",
      "3816  2019-01-14 15:02:44.321 -0.051060 -0.741592 -0.370368  105.773630   \n",
      "3817   2019-01-14 15:02:44.48  0.216578 -0.631654 -0.805722  105.773630   \n",
      "3818   2019-01-14 15:02:44.64 -0.140476 -0.683447 -0.204729  105.773630   \n",
      "3819  2019-01-14 15:02:44.802 -0.238687 -0.692242 -0.066451  105.773630   \n",
      "\n",
      "            AI  \n",
      "0     1.000000  \n",
      "1     1.000000  \n",
      "2     1.000000  \n",
      "3     1.000000  \n",
      "4     1.000000  \n",
      "5     1.000000  \n",
      "6     1.000000  \n",
      "7     1.000000  \n",
      "8     1.000000  \n",
      "9     1.000000  \n",
      "10    0.999982  \n",
      "11    0.999984  \n",
      "12    0.999982  \n",
      "13    0.999988  \n",
      "14    1.000045  \n",
      "15    1.000075  \n",
      "16    1.000087  \n",
      "17    1.000094  \n",
      "18    1.000096  \n",
      "19    1.000088  \n",
      "20    1.000095  \n",
      "21    1.000089  \n",
      "22    1.000091  \n",
      "23    1.000097  \n",
      "24    1.000061  \n",
      "25    1.000047  \n",
      "26    1.000044  \n",
      "27    1.000058  \n",
      "28    1.000061  \n",
      "29    1.000062  \n",
      "...        ...  \n",
      "3790  1.035018  \n",
      "3791  1.036179  \n",
      "3792  1.032006  \n",
      "3793  1.021905  \n",
      "3794  1.019608  \n",
      "3795  1.018733  \n",
      "3796  1.029428  \n",
      "3797  1.018849  \n",
      "3798  1.018513  \n",
      "3799  1.018731  \n",
      "3800  1.020076  \n",
      "3801  1.030858  \n",
      "3802  1.030835  \n",
      "3803  1.031050  \n",
      "3804  1.031715  \n",
      "3805  1.030998  \n",
      "3806  1.019621  \n",
      "3807  1.027452  \n",
      "3808  1.039931  \n",
      "3809  1.052863  \n",
      "3810  1.068243  \n",
      "3811  1.058348  \n",
      "3812  1.051795  \n",
      "3813  1.058853  \n",
      "3814  1.075461  \n",
      "3815  1.072571  \n",
      "3816  1.143997  \n",
      "3817  1.137957  \n",
      "3818  1.166724  \n",
      "3819  1.163991  \n",
      "\n",
      "[3820 rows x 6 columns]\n",
      "Loading 1002's data\n",
      "                    timestamp         x         y         z          HR  \\\n",
      "0     2019-01-14 15:19:07.994 -0.781414 -0.576685  0.092592  115.000565   \n",
      "1     2019-01-14 15:19:08.155 -0.767733 -0.678805  0.060832  115.000565   \n",
      "2     2019-01-14 15:19:08.321 -0.777993 -0.608933  0.089660  116.214920   \n",
      "3     2019-01-14 15:19:08.477 -0.764312 -0.649977  0.083308  116.214920   \n",
      "4     2019-01-14 15:19:08.637 -0.750631 -0.603559  0.052526  116.214920   \n",
      "5     2019-01-14 15:19:08.797 -0.805844 -0.573265  0.103342  116.214920   \n",
      "6     2019-01-14 15:19:08.957 -0.795095 -0.757472  0.061809  116.214920   \n",
      "7     2019-01-14 15:19:09.118 -0.728644 -0.538573  0.021743  116.214920   \n",
      "8      2019-01-14 15:19:09.29 -0.858614 -0.618217  0.055458  116.214920   \n",
      "9      2019-01-14 15:19:09.45 -0.785323 -0.549811  0.075002  116.361130   \n",
      "10      2019-01-14 15:19:09.6 -0.764801 -0.648511  0.066696  116.361130   \n",
      "11    2019-01-14 15:19:09.761 -0.799492 -0.555186  0.169304  116.361130   \n",
      "12    2019-01-14 15:19:09.922 -0.713985 -0.751608  0.089660  116.361130   \n",
      "13    2019-01-14 15:19:10.084 -0.769198 -0.985654  0.365238  116.361130   \n",
      "14    2019-01-14 15:19:10.242 -0.608933 -0.690532  0.315888  116.361130   \n",
      "15    2019-01-14 15:19:10.405 -0.383194 -0.769687  0.405304  116.361130   \n",
      "16    2019-01-14 15:19:10.571 -0.237099 -0.561538  0.168327  112.708880   \n",
      "17    2019-01-14 15:19:10.727 -0.476519 -0.669521  0.176633  112.708880   \n",
      "18    2019-01-14 15:19:10.886 -1.255368 -0.677828  0.254811  112.708880   \n",
      "19    2019-01-14 15:19:11.047 -1.052594 -0.220486  0.350091  112.708880   \n",
      "20    2019-01-14 15:19:11.207 -1.036469 -0.142308  0.337876  112.708880   \n",
      "21    2019-01-14 15:19:11.368 -0.814151 -0.210714  0.088195  112.708880   \n",
      "22    2019-01-14 15:19:11.528 -0.866432 -0.183352  0.133636  112.708880   \n",
      "23    2019-01-14 15:19:11.689 -1.136146 -0.073414  0.378919  105.792816   \n",
      "24     2019-01-14 15:19:11.85 -1.030606  0.155134  0.245039  105.792816   \n",
      "25    2019-01-14 15:19:12.012 -0.877670 -0.296710  0.183474  105.792816   \n",
      "26    2019-01-14 15:19:12.172 -0.976370 -0.313323  0.137056  105.792816   \n",
      "27    2019-01-14 15:19:12.332 -0.970507 -0.349480  0.137056  105.792816   \n",
      "28    2019-01-14 15:19:12.494 -0.936793 -0.318209  0.197155  105.792816   \n",
      "29    2019-01-14 15:19:12.655 -0.846888 -0.297687  0.140965  105.792816   \n",
      "...                       ...       ...       ...       ...         ...   \n",
      "2623  2019-01-14 15:26:09.457 -0.413733 -0.179443  0.036279  121.566180   \n",
      "2624  2019-01-14 15:26:09.619 -2.057426 -0.532221  0.230747  121.566180   \n",
      "2625  2019-01-14 15:26:09.779 -0.981501  0.014903  0.422772  121.566180   \n",
      "2626  2019-01-14 15:26:09.939 -0.627256 -0.645579  0.240520  121.566180   \n",
      "2627  2019-01-14 15:26:10.101 -1.545848 -0.212180 -0.056435  122.090030   \n",
      "2628  2019-01-14 15:26:10.261 -1.240954 -0.042143  0.100776  122.090030   \n",
      "2629  2019-01-14 15:26:10.423 -0.940946  0.459052  0.229770  122.090030   \n",
      "2630  2019-01-14 15:26:10.582 -0.940946 -0.235633 -0.039822  122.090030   \n",
      "2631  2019-01-14 15:26:10.742 -0.272524 -0.170159  0.399807  122.090030   \n",
      "2632  2019-01-14 15:26:10.903 -0.987364 -0.183352  0.271791  122.090030   \n",
      "2633  2019-01-14 15:26:11.069 -0.947786 -0.432544  0.401762  122.090030   \n",
      "2634  2019-01-14 15:26:11.226 -0.788987 -0.540528  0.199476  116.478780   \n",
      "2635  2019-01-14 15:26:11.385 -0.750387 -0.425215  0.394921  116.478780   \n",
      "2636  2019-01-14 15:26:11.546 -1.698784 -0.316255  0.098822  116.478780   \n",
      "2637  2019-01-14 15:26:11.707 -1.009351 -0.345571 -0.033470  116.478780   \n",
      "2638  2019-01-14 15:26:11.868 -0.918958 -0.404693  0.003542  116.478780   \n",
      "2639  2019-01-14 15:26:12.028 -0.800714 -0.427170  0.005008  116.478780   \n",
      "2640  2019-01-14 15:26:12.189 -1.160821 -0.299153 -0.003176  116.478780   \n",
      "2641   2019-01-14 15:26:12.35 -0.875472 -0.438896  0.228304  113.673160   \n",
      "2642  2019-01-14 15:26:12.511 -0.884267 -0.357298  0.289381  113.673160   \n",
      "2643  2019-01-14 15:26:12.673 -0.859836 -0.381729  0.478474  113.673160   \n",
      "2644  2019-01-14 15:26:12.834 -0.806577 -0.239542  0.423749  113.673160   \n",
      "2645  2019-01-14 15:26:12.992 -0.824656 -0.361695  0.439385  113.673160   \n",
      "2646  2019-01-14 15:26:13.153 -0.722047 -0.301596  0.336288  113.673160   \n",
      "2647  2019-01-14 15:26:13.315 -0.828565 -0.389546  0.362184  113.673160   \n",
      "2648  2019-01-14 15:26:13.476 -1.586403 -0.422283  0.419352  113.673160   \n",
      "2649  2019-01-14 15:26:13.636 -1.134436 -0.477497  0.151103  113.673160   \n",
      "2650  2019-01-14 15:26:13.796 -0.611621 -0.308437  0.044097  113.673160   \n",
      "2651  2019-01-14 15:26:13.956 -0.980035 -0.262996  0.040677  113.673160   \n",
      "2652  2019-01-14 15:26:14.118 -1.734941 -0.342640  0.204851  113.673160   \n",
      "\n",
      "            AI  \n",
      "0     1.000000  \n",
      "1     1.000000  \n",
      "2     1.000000  \n",
      "3     1.000000  \n",
      "4     1.000000  \n",
      "5     1.000000  \n",
      "6     1.000000  \n",
      "7     1.000000  \n",
      "8     1.000000  \n",
      "9     1.000000  \n",
      "10    1.001801  \n",
      "11    1.001758  \n",
      "12    1.002067  \n",
      "13    1.002810  \n",
      "14    1.009260  \n",
      "15    1.011157  \n",
      "16    1.017376  \n",
      "17    1.023837  \n",
      "18    1.023244  \n",
      "19    1.033316  \n",
      "20    1.043478  \n",
      "21    1.053867  \n",
      "22    1.059296  \n",
      "23    1.062159  \n",
      "24    1.062995  \n",
      "25    1.069505  \n",
      "26    1.054099  \n",
      "27    1.036060  \n",
      "28    1.022198  \n",
      "29    1.012935  \n",
      "...        ...  \n",
      "2623  1.140374  \n",
      "2624  1.156175  \n",
      "2625  1.149250  \n",
      "2626  1.155821  \n",
      "2627  1.164791  \n",
      "2628  1.160457  \n",
      "2629  1.132771  \n",
      "2630  1.144663  \n",
      "2631  1.100746  \n",
      "2632  1.122669  \n",
      "2633  1.122625  \n",
      "2634  1.111380  \n",
      "2635  1.072823  \n",
      "2636  1.072806  \n",
      "2637  1.082875  \n",
      "2638  1.072047  \n",
      "2639  1.069432  \n",
      "2640  1.052285  \n",
      "2641  1.053468  \n",
      "2642  1.034308  \n",
      "2643  1.033475  \n",
      "2644  1.035307  \n",
      "2645  1.036870  \n",
      "2646  1.036421  \n",
      "2647  1.018515  \n",
      "2648  1.016104  \n",
      "2649  1.030147  \n",
      "2650  1.028600  \n",
      "2651  1.029709  \n",
      "2652  1.032015  \n",
      "\n",
      "[2653 rows x 6 columns]\n",
      "Finished loading\n"
     ]
    }
   ],
   "source": [
    "itr = len(all_subjects)\n",
    "\n",
    "TRIAXIAL = 3\n",
    "itr_count = 0\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "\n",
    "for idx in range(itr):\n",
    "\n",
    "    subject_id = identify_subj_id(idx)\n",
    "    print(\"Loading {0}'s data\".format(subject_id))\n",
    "\n",
    "    df_timer, rec_date, start_time, end_time = load_timer(subject_id)\n",
    "    df1, ai1, ts, lb_color = ai(subject_id)\n",
    "\n",
    "    # get a list of dataframe in which there are 5 types of activity\n",
    "    df_list, label_dict = group_dataframe(df1, df_timer)\n",
    "    label_list = sorted(list(label_dict.keys()))\n",
    "\n",
    "#     plot_grouped_df(df_list, label_dict)\n",
    "#     plot_ai(df1, ts, lb_color)\n",
    "#     print(df1)\n",
    "\n",
    "    X_i, y_i = get_training_data(df_list, label_dict)\n",
    "    subj_i = [subject_id for i in range(len(X_i))]\n",
    "\n",
    "    if(idx==0):\n",
    "        X_all = X_i\n",
    "        y_all = y_i\n",
    "        subj_all = subj_i\n",
    "    else:\n",
    "        X_all = np.vstack((X_all, X_i))\n",
    "        y_all = np.hstack((y_all, y_i))\n",
    "        subj_all = np.hstack((subj_all, subj_i))\n",
    "\n",
    "print(\"Finished loading\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
