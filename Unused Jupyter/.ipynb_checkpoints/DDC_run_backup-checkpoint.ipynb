{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7KG93zTnlu0"
   },
   "source": [
    "# Import Core Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4AvIBQQQMGyA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "\n",
    "from os import listdir, walk\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Im12HZ4kMGyQ"
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'load_dataset.ipynb.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "%run load_dataset.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wyuXI7owzjG4"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'preprocess_for_SVM.ipynb.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "# includes wavelet denoising, normalization, PCA, LDA, SVD, etc.\n",
    "%run preprocess_for_SVM.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ac3q3J-hXiY"
   },
   "source": [
    "# Function Call *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denoise the signal using wavelet transform\n",
    "# wavelet_output = wavelet_smooth(X_all)\n",
    "# X_w = np.array(wavelet_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_label_list = [1,2,3,0,4,5]\n",
    "new_label_dict = {\n",
    "    1: 'sit',\n",
    "    2: 'sleep',\n",
    "    3: 'stand',\n",
    "    0: 'downstairs',\n",
    "    4: 'upstairs',\n",
    "    5: 'walk'\n",
    "}\n",
    "\n",
    "colors = ['r','g','b','navy','turquoise','darkorange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_grouping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4a7d0fe3c342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# group X_all and y_all from load_dataset.ipynb by labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_grouping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubj_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_label_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# normalize X_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label_grouping' is not defined"
     ]
    }
   ],
   "source": [
    "# group X_all and y_all from load_dataset.ipynb by labels\n",
    "X_label, y_label = label_grouping(X_all, y_all, subj_all, new_label_list)\n",
    "\n",
    "# normalize X_label\n",
    "X_norm = normalize_data(X_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Plot for each Activity and Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_all_label(X_label, y_all, new_label_list, new_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_all_label(X_norm, y_all, new_label_list, new_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate roll, pitch, yaw\n",
    "roll, pitch, yaw = calc_rpy(X_all, subject_id, colors)\n",
    "rpy = np.array([roll, pitch, yaw]).transpose()\n",
    "\n",
    "print(rpy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack all list in X_norm into one long numpy list\n",
    "X_norm_all = []\n",
    "first = True\n",
    "\n",
    "for lb in range(len(label_list)):\n",
    "    for s in range(len(all_subjects)):\n",
    "        if(first):\n",
    "            X_norm_all = X_norm[lb][s]\n",
    "            first = False\n",
    "        else:\n",
    "            X_norm_all = np.vstack((X_norm_all, X_norm[lb][s]))\n",
    "\n",
    "print(X_norm_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# apply PCA and LDA to X_norm and rpy\n",
    "print(\"PCA\")\n",
    "X_pca = apply_pca(X_all, y_all, label_list)\n",
    "X_z_pca = apply_pca(X_norm_all, y_all, label_list)\n",
    "rpy_pca = apply_pca(rpy, y_all, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"LDA\")\n",
    "# X_norm_lda = apply_lda(X_all, y_all, label_list)\n",
    "# X_z_lda = apply_lda(X_norm_all, y_all, label_list)\n",
    "# rpy_lda = apply_lda(rpy, y_all, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"SVD\")\n",
    "# u, s, vh = apply_svd(X_norm_all, y_all, label_list)\n",
    "# u_r, s_r, vh_r = apply_svd(X_norm_all, y_all, label_list)\n",
    "\n",
    "# print(u_r.shape, s_r.shape, vh_r.shape)\n",
    "# print(s_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_overlapping(X, y):\n",
    "    length = X.shape[0]\n",
    "    X_new = []\n",
    "    y_new = []\n",
    "    window_length = 60  # 9.6 seconds\n",
    "    \n",
    "    for i in range(length):\n",
    "        X_temp = []\n",
    "        for j in range(window_length):\n",
    "            if(i+j<length):\n",
    "                X_temp.append(X[i+j])\n",
    "        \n",
    "        if(i+window_length-1<length):\n",
    "            X_new.append(X_temp)\n",
    "            y_new.append(y[i+window_length-1])\n",
    "    \n",
    "    return np.array(X_new), np.array(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_xyz(X):\n",
    "    X_concat = []\n",
    "    for X_i in X:\n",
    "        X_tp = X_i.transpose()\n",
    "        X_stack = np.hstack((X_tp[0],X_tp[1],X_tp[2]))\n",
    "        X_concat.append(X_stack)\n",
    "\n",
    "    return np.array(X_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_subj(X, y, all_subjects):\n",
    "    n_labels = 6\n",
    "    test_size = 0.3\n",
    "    \n",
    "    train_size = 1 - test_size\n",
    "    train_length = int(len(all_subjects)*train_size) \n",
    "    \n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    \n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    \n",
    "    for i in range(n_labels):\n",
    "        X_temp = []\n",
    "        y_temp = []\n",
    "        for j in range(train_length):\n",
    "            if(j==0):\n",
    "                X_temp = X[i][j]\n",
    "                y_temp = y[i][j]\n",
    "            else:\n",
    "                X_temp = np.vstack((X_temp, X[i][j]))\n",
    "                y_temp = np.hstack((y_temp, y[i][j]))\n",
    "                \n",
    "        X_train.append(np.array(X_temp))\n",
    "        y_train.append(np.array(y_temp))\n",
    "        \n",
    "        X_temp_2 = []\n",
    "        y_temp_2 = []\n",
    "        for j in range(train_length, len(all_subjects)):\n",
    "            if(j==train_length):\n",
    "                X_temp_2 = X[i][j]\n",
    "                y_temp_2 = y[i][j]\n",
    "            else:\n",
    "                X_temp_2 = np.vstack((X_temp_2, X[i][j]))\n",
    "                y_temp_2 = np.hstack((y_temp_2, y[i][j]))\n",
    "        X_test.append(np.array(X_temp_2))\n",
    "        y_test.append(np.array(y_temp_2))\n",
    "        \n",
    "    return np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_label(X):\n",
    "    X_concat = []\n",
    "    for X_lb in X:\n",
    "        X_temp = []\n",
    "        for i in range(len(X_lb)):\n",
    "            if(i==0):\n",
    "                X_temp = X_lb[i]\n",
    "            else:\n",
    "                X_temp = np.vstack((X_temp, X_lb[i]))\n",
    "                \n",
    "        if(len(X_concat)==0):\n",
    "            X_concat = X_temp\n",
    "        else:\n",
    "            X_concat = np.vstack((X_concat, X_temp))\n",
    "            \n",
    "    return np.array(X_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpy_label, y_label = label_grouping(rpy_pca, y_all, subj_all, new_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, X_test_, y_train_, y_test_ = split_subj(rpy_label, y_label, all_subjects)\n",
    "\n",
    "X_train = concat_label(X_train_)\n",
    "X_test = concat_label(X_test_)\n",
    "\n",
    "y_train = concat_label(y_train_)\n",
    "y_test = concat_label(y_test_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start from Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpy_ol, y_ol = make_overlapping(rpy_pca, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ol = concat_xyz(X_train_ol_)\n",
    "X_test_ol = concat_xyz(X_test_ol_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test_ol.shape)\n",
    "print(X_test_ol.shape)\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# s1 = 0\n",
    "# for i in range(6):\n",
    "#     s1 += X_train[i].shape[0]\n",
    "#     print(X_train[i].shape)\n",
    "\n",
    "# print(s1)\n",
    "\n",
    "# s2 = 0\n",
    "# for i in range(6):\n",
    "#     s2 += X_test[i].shape[0]\n",
    "#     print(X_test[i].shape)\n",
    "    \n",
    "# print(s2)\n",
    "# print(s1+s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data before classification\n",
    "X_svm = X_train_ol\n",
    "y_svm = y_train_ol\n",
    "# y_svm = y_svm.reshape((y_svm.shape[-1],))\n",
    "y_svm = y_svm.reshape((y_svm.shape[0],))\n",
    "\n",
    "print(X_svm.shape, y_svm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data and testing data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_svm, y_svm, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SVM to classify activities\n",
    "svm_model = svm_classifier(X_svm, y_svm)\n",
    "print(\"Finished classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_model.predict(X_test_ol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test_ol, y_pred)\n",
    "\n",
    "print(acc)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run eval_score.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['downstairs','sit','sleep','stand','upstairs','walk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_conf_matrix(y_test, y_pred, LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_clf_report(y_test, y_pred, LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DcBJlYGj1lf_"
   },
   "source": [
    "### 1001\n",
    "* Accuracy of original data: 0.6356\n",
    "\n",
    "* Accuracy of PCA with original data: 0.6041\n",
    "\n",
    "* Accuracy of PCA without original data: 0.6400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All subjects ( test_size=0.3 )\n",
    "* Accuracy of PCA without original data: 0.6542"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gum1EHUr8_xY"
   },
   "source": [
    "## Colors Note\n",
    "\n",
    "* NaN: Grey\n",
    "* Stand: Red\n",
    "* Sit: Green\n",
    "* Sleep: Yellow\n",
    "* Walk: Blue\n",
    "* Walk Downstairs: Orange\n",
    "* Walk Upstairs: Purple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DDC_run.ipynb",
   "provenance": [
    {
     "file_id": "1uW9RzCQha3RZ_wzM_gLxhAN7ytclHWHC",
     "timestamp": 1548220076491
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
